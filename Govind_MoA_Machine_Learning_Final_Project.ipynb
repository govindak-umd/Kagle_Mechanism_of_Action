{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action (MoA) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some of the important terms used in the headings of the tables are presented here:\n",
    "    \n",
    "    g - : signifies gene expression data\n",
    "    c - : signifies cell expression data\n",
    "    cp_type : indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\n",
    "    NOTE: (samples with control perturbations don't have MoAs)\n",
    "    cp_time - treatment duration (24,48,72) Hours\n",
    "    cp_dose - Dosage - HIGH or LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the multi label stratified k-fold \n",
    "# cross validator\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Initial random imports\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Importing pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device_code = 'cuda'\n",
    "else:\n",
    "    device_code = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the seed, so that every time the seed is started from the same number\n",
    "\n",
    "def set_seed_characteristics(seed=55):\n",
    "    # Setting a random seed value\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    # for guaranteering the reproducability of numbers by setting seed for NumPy\n",
    "    \n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    # for setting the seed for cuda or cpu\n",
    "    \n",
    "    torch.manual_seed(seed) \n",
    "\n",
    "    # To ensure that Pytorch doesnt just switch to the fastest possible algorithm but \n",
    "    # ensures that it selects a deterministic algorithm\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.read_csv('input/train_features.csv')\n",
    "# Reading the head rows and columns of train features\n",
    "training_features_head = training_features.head()\n",
    "\n",
    "training_targets_scored = pd.read_csv('input/train_targets_scored.csv')\n",
    "# Reading the head rows and columns of train targets scored\n",
    "training_targets_scored_head = training_targets_scored.head()\n",
    "\n",
    "testing_features = pd.read_csv('input/test_features.csv')\n",
    "# Reading the head rows and columns of train targets non-scored\n",
    "testing_features_head = testing_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - training features \n",
    "training_features_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - train targets scored \n",
    "training_targets_scored_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303 -0.1193   \n",
       "1 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690 -0.5382   \n",
       "2 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530 -1.0140   \n",
       "3 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325 -0.9005   \n",
       "4 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742  1.0900   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2  0.8662  1.0160  0.4924 -0.1942  \n",
       "3  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4 -0.2962 -0.5313  0.9931  1.8380  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - test features\n",
    "testing_features_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset classes, training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch data loader implementation of MoA dataset\n",
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return train_tensor_dictionary\n",
    "\n",
    "# Pytorch data loader implementation of test dataset\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        test_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return test_tensor_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch model for the MoA determination\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    # Instantiaing all the models before utilizing\n",
    "    # them later in the forward function.\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        \n",
    "        # super keyword used to access data from the parent\n",
    "        # pytorch.nn.Module class\n",
    "        super(Model, self).__init__()\n",
    "        # Applying batch normalization. This is done to standardize\n",
    "        # the input for each mini batches and will help reduce the\n",
    "        # number of epochs for which the training is done. This limits\n",
    "        # the covariate shift (this is the value by which the hidden\n",
    "        # layer values shift around) and allows to learn from a more \n",
    "        # stable set of data. Sometimes, it also allows for a\n",
    "        # higher learning rate.This is also used for regularization\n",
    "        # and helps reduce over fitting. Generally, if batch \n",
    "        # normalization is used, you can use a smaller dropout,\n",
    "        # which in turn means that lesser layers can be lost \n",
    "        # in every step.\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)        \n",
    "        # For regularization purposes the dropout is set\n",
    "        # This is done by setting a probablity. Random \n",
    "        # neural networks are picked at a probablity, say p\n",
    "        # or dropped at a probablity of 1-p. This is essential \n",
    "        # to prevent overfitiing of the model and also reduces\n",
    "        # the computation time. A fully connected neural network, if\n",
    "        # run without dropout will start forming dependancies between\n",
    "        # each other and this can lead to over-fitting.\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        # nn.utils.weight_norm : This is weight normalization. Usually,\n",
    "        #                        faster than batch normalization\n",
    "        # nn.Linear : Applying linear transform to the incoming data\n",
    "        #             and creates a single layer feed forward network.\n",
    "        # input size : num_features\n",
    "        # output size : hidden_size\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        # input size : hidden_size\n",
    "        # output size : hidden_size\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        # input size : hidden_size\n",
    "        # output size : num_targets\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    # The forward function basically defines the model\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def trainingFunction(model, optimizer, scheduler, lossFunction, trainloader, device_code):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for training_data in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = training_data['x'].to(device_code), training_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        training_loss += loss.item()    \n",
    "    training_loss /= len(trainloader) \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate the model\n",
    "def validationFunction(model, lossFunction, validationloader, device_code):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_predictions = []   \n",
    "    for validation_data in validationloader:\n",
    "        inputs, targets = validation_data['x'].to(device_code), validation_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        validation_loss += loss.item()\n",
    "        validation_predictions.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    validation_loss /= len(validationloader)\n",
    "    validation_predictions = np.concatenate(validation_predictions)\n",
    "    return validation_loss, validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the inference function\n",
    "def inferenceFunction(model, inferenceloader, device_code):\n",
    "    model.eval()\n",
    "    inferences = [] \n",
    "    for data in inferenceloader:\n",
    "        inputs = data['x'].to(device_code)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        inferences.append(outputs.sigmoid().detach().cpu().numpy())   \n",
    "    inferences = np.concatenate(inferences)  \n",
    "    return inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dummy inserts to the cp_time and cp_dose columns\n",
    "# Usually done to categorical variables\n",
    "def addDummies(data):\n",
    "    dummy_data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed_characteristics(seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating out the Gene expression Column and Cell Viability Column\n",
    "\n",
    "gene_expression = [g for g in training_features.columns if g.startswith('g-')]\n",
    "cell_viability = [c for c in training_features.columns if c.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our dimensions are really high, we can resort to \n",
    "# using PCA for dimensionality reduction, but is still able \n",
    "# to capture the characteristics of the data.\n",
    "\n",
    "# Now, this can be done by choosing a random dimension, and \n",
    "# having the same random state as before. By doing this\n",
    "# we observe that we do not encounter\n",
    "# any 'nan' errors during training.\n",
    "\n",
    "# Doing PCA for the Gene expression data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_genes = 20\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[gene_expression]), pd.DataFrame(testing_features[gene_expression])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_genes number of columns\n",
    "pca_genes = PCA(n_components = random_pca_dimension_genes, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_genes.fit_transform(data[gene_expression])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_genes = data_pca[:training_features.shape[0]] \n",
    "test_pca_genes = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_genes = pd.DataFrame(train_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "test_pca_genes = pd.DataFrame(test_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_genes), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_genes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing PCA for the Cell Viability Data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_cells = 32\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[cell_viability]), pd.DataFrame(testing_features[cell_viability])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_cells number of columns\n",
    "pca_cells = PCA(n_components = random_pca_dimension_cells, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_cells.fit_transform(data[cell_viability])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_cells = data_pca[:training_features.shape[0]]\n",
    "test_pca_cells = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_cells = pd.DataFrame(train_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "test_pca_cells = pd.DataFrame(test_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_cells), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_cells), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a desired threshold to calculate the VarianceThreshold.\n",
    "# As per the math all the Features with a training-set variance \n",
    "# lower than this threshold will be removed.\n",
    "variancethreshold = VarianceThreshold(threshold=0.7)\n",
    "\n",
    "# Combining training and test features to create a single dataset\n",
    "combined_data = training_features.append(testing_features)\n",
    "\n",
    "# Fits to the data, before transforming it\n",
    "combined_data_transformed = variancethreshold.fit_transform(combined_data.iloc[:, 4:])\n",
    "\n",
    "# Extracting the training and the testing data out of the\n",
    "# transformed data\n",
    "training_features_transformed = combined_data_transformed[ : training_features.shape[0]]\n",
    "testing_features_transformed = combined_data_transformed[-testing_features.shape[0] : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "training_features = pd.DataFrame(training_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "training_features = pd.concat([training_features, pd.DataFrame(training_features_transformed)], axis=1)\n",
    "\n",
    "# Extracting the testing features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "\n",
    "testing_features = pd.DataFrame(testing_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "testing_features = pd.concat([testing_features, pd.DataFrame(testing_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the columns\n",
    "\n",
    "train = training_features.merge(training_targets_scored, on='sig_id')\n",
    "\n",
    "# Removing rows with cp_type as ctl_vehicle \n",
    "# since control perturbations have no MoAs\n",
    "# We are also manually setting the drop type as \n",
    "# true because we do not want to include them back \n",
    "# as a new column.\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# Naturally, we have to get rid of them from the test dataset \n",
    "# as well\n",
    "\n",
    "test = testing_features[testing_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the columns of the drugs that are sold from\n",
    "# the train pandas dataframe\n",
    "\n",
    "target = train[training_targets_scored.columns]\n",
    "\n",
    "# Now that the ctl_vehicle drugs have been removed, we do not need\n",
    "# cp_type. So we can go ahead and remove that columns as well.\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "# extracting the columns in the targets \n",
    "\n",
    "target_columns = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilabel stratified K Fold import causes a small warning and we do not want\n",
    "# to show that in the notebook.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "folds = train.copy()\n",
    "number_of_folds = 3\n",
    "\n",
    "# creating a 3 fold multilabel stratified K Fold\n",
    "multilabel_k_fold = MultilabelStratifiedKFold(n_splits = number_of_folds)\n",
    "\n",
    "# Standard k fold splitting. Here we are splitting into 3 folds\n",
    "\n",
    "for fol, (train_folds, validation_folds) in enumerate(multilabel_k_fold.split(X=train, y=target)):\n",
    "    folds.loc[validation_folds, 'kfold'] = int(fol)\n",
    "    \n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# Isolating out the feature columns. This is done by first \n",
    "# Isolating the columns that are not present in the target\n",
    "# followed by extracting the columns except the sig_id and \n",
    "# kfold.\n",
    "\n",
    "feature_columns = [c for c in addDummies(folds).columns if c not in target_columns]\n",
    "feature_columns = [c for c in feature_columns if c not in ['kfold','sig_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "max_epochs = 15\n",
    "# When training neural networks, it is common to use \n",
    "# weight decay where after each update, the weights \n",
    "# are multiplied by a factor slightly less than 1\n",
    "WEIGHT_DECAY = 1e-5\n",
    "# deciding the initial learning rate\n",
    "# It controls how quickly or slowly a neural\n",
    "# network model can learn a model or a problem.\n",
    "lr = 1e-3\n",
    "EARLY_STOPPING_STEPS = 11\n",
    "# Boolean to decide on stopping early when the \n",
    "# validation_loss > best_loss\n",
    "EARLY_STOP = True\n",
    "# number of features corresponding to the columns in the\n",
    "# targets\n",
    "num_features=len(feature_columns)\n",
    "# number of targets corresponding to the columns in the\n",
    "# features\n",
    "num_targets=len(target_columns)\n",
    "# in between neural netwrok size\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the training functions and performing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot validation loss\n",
    "valid_loss_list = []\n",
    "# to plot the training loss\n",
    "train_loss_list = []\n",
    "# to plot the best recorded loss\n",
    "best_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    # declaring the list as global to plot validation loss\n",
    "    global valid_loss_list\n",
    "    # declaring the training loss list as global to plot\n",
    "    # the training loss\n",
    "    global train_loss_list\n",
    "    # declaring the best loss list as global to plot the\n",
    "    # best losses recorded\n",
    "    global best_loss_list\n",
    "    \n",
    "    # setting the seed to start from the same number as \n",
    "    # explained previously\n",
    "    set_seed_characteristics(seed)\n",
    "    \n",
    "    # adding dummy variables to the training set\n",
    "    train = addDummies(folds)\n",
    "    # adding dummy variables to the test set\n",
    "    test_ = addDummies(test)\n",
    "    \n",
    "    # extracting the training rows numbers for the\n",
    "    # respective k fold values\n",
    "#     trn_idx = train[train['kfold'] != fold].index\n",
    "\n",
    "    # extracting the validating rows numbers for the\n",
    "    # respective k fold values\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    # Dropping all the rows from the training set\n",
    "    # that does not belong to this kth fold\n",
    "    train_necessary_rows = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    # Dropping all the rows from the valiadtion set\n",
    "    # that does not belong to this kth fold\n",
    "    valid_necessary_rows = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # splitting the x and y values for training set\n",
    "    train_features, train_targets  = train_necessary_rows[feature_columns].values, train_necessary_rows[target_columns].values\n",
    "    # splitting the x and y values for test set\n",
    "    validation_features, validation_targets =  valid_necessary_rows[feature_columns].values, valid_necessary_rows[target_columns].values\n",
    "    \n",
    "    # Converting the training data to standard pytorch \n",
    "    # dataset class format\n",
    "    train_dataset = MoADataset(train_features, train_targets)\n",
    "    \n",
    "    # Converting the validation data to standard pytorch \n",
    "    # dataset class format\n",
    "    valid_dataset = MoADataset(validation_features, validation_targets)\n",
    "    \n",
    "    # calling the pytorch data loading utility for the\n",
    "    # training set\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # calling the pytorch data loading utility for the\n",
    "    # validation set  \n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Declaring the model and can be tuned here\n",
    "    # using the hyper parameters\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # moving the model to GPU if available,\n",
    "    # else will run it on CPU itself\n",
    "    model.to(device_code)\n",
    "    \n",
    "    # A standard optimizer. Adam optimizer is widely used\n",
    "    # because it combines the advantages of the Adaptive gradient\n",
    "    # algorithm and the root mean square propogation. Basically, it does\n",
    "    # not stick to one learning rate and adapts it to the problem. \n",
    "    # It is widely known to offer good results really fast.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # We use a learning rate scheduler to converge to the lowest\n",
    "    # loss faster. This is also seen to provide higher accuracy.\n",
    "    # This can be tuned.\n",
    "    # Some of the optimizers I tried here are\n",
    "    # optim.lr_scheduler.OneCycleLR\n",
    "    # optim.lr_scheduler.StepLR\n",
    "    \n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.05, div_factor=1.5e3, \n",
    "                                              max_lr=1e-2, epochs=max_epochs, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    # after research I saw that the Binary cross\n",
    "    # entroy loss with sigmoid later works well\n",
    "    lossFunction = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # stops when the error starts increaseing\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    steps_before_early_stop = 0\n",
    "    # general out of fold array shape\n",
    "    out_of_fold = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    # declaring a very high value as an \n",
    "    # initial loss for each kth fold\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    # looping through the epochs\n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        # training the model\n",
    "        training_loss = trainingFunction(model, optimizer,scheduler, lossFunction, trainloader, device_code)\n",
    "        print(f\"FOLD: {fold}> EPOCH: {epoch}>>> training_loss: {training_loss}\")\n",
    "        train_loss_list.append(training_loss)\n",
    "        validation_loss, validation_predictions = validationFunction(model, lossFunction, validloader, device_code)\n",
    "        print(f\"FOLD: {fold}> EPOCH: {epoch}>>> validation_loss: {validation_loss}\")\n",
    "        valid_loss_list.append(validation_loss)\n",
    "        \n",
    "        # checking if the loss is decreasing\n",
    "        if validation_loss < best_loss:\n",
    "            best_loss = validation_loss\n",
    "            best_loss_list.append(best_loss)\n",
    "            # Updating the out of fold predictions\n",
    "            out_of_fold[val_idx] = validation_predictions\n",
    "            # saving the model and data for this kth fold\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        # Handling the increasing loss by calling \n",
    "        # early stopping\n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            # breaks out of the loop when this happens\n",
    "            steps_before_early_stop += 1\n",
    "            if (steps_before_early_stop >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    # extracting the x_test\n",
    "    x_test = test_[feature_columns].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(num_features=num_features,num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # uploading the saved data for this kth fold\n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    # again uploading the model to GPU, if available\n",
    "    model.to(device_code)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    # evaluates the model\n",
    "    predictions = inferenceFunction(model, testloader, device_code)\n",
    "    \n",
    "    return out_of_fold, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(number_of_folds, seed):\n",
    "    # standard size for the out of fold predictions\n",
    "    out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "    # same size for all of the predictions\n",
    "    predictions = np.zeros((len(test), len(target_columns)))\n",
    "    \n",
    "    for fold in range(number_of_folds):\n",
    "        out_of_fold_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        # adding all the predictions\n",
    "        predictions += pred_ / number_of_folds\n",
    "        # adding all the out of fold predictions\n",
    "        out_of_fold += out_of_fold_\n",
    "        \n",
    "    return out_of_fold, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0> EPOCH: 0>>> training_loss: 0.22010354647274621\n",
      "FOLD: 0> EPOCH: 0>>> validation_loss: 0.023666419461369513\n",
      "FOLD: 0> EPOCH: 1>>> training_loss: 0.019186532165546083\n",
      "FOLD: 0> EPOCH: 1>>> validation_loss: 0.018038645216628263\n",
      "FOLD: 0> EPOCH: 2>>> training_loss: 0.01805579964494471\n",
      "FOLD: 0> EPOCH: 2>>> validation_loss: 0.017761908309615177\n",
      "FOLD: 0> EPOCH: 3>>> training_loss: 0.017867758304824215\n",
      "FOLD: 0> EPOCH: 3>>> validation_loss: 0.017857895232737064\n",
      "FOLD: 0> EPOCH: 4>>> training_loss: 0.017903095359332436\n",
      "FOLD: 0> EPOCH: 4>>> validation_loss: 0.01778543307243482\n",
      "FOLD: 0> EPOCH: 5>>> training_loss: 0.017865373090104764\n",
      "FOLD: 0> EPOCH: 5>>> validation_loss: 0.01771177589569403\n",
      "FOLD: 0> EPOCH: 6>>> training_loss: 0.017801803337434495\n",
      "FOLD: 0> EPOCH: 6>>> validation_loss: 0.017754284640693146\n",
      "FOLD: 0> EPOCH: 7>>> training_loss: 0.017625045023175308\n",
      "FOLD: 0> EPOCH: 7>>> validation_loss: 0.01749473760795334\n",
      "FOLD: 0> EPOCH: 8>>> training_loss: 0.017523331644916377\n",
      "FOLD: 0> EPOCH: 8>>> validation_loss: 0.01738321535775195\n",
      "FOLD: 0> EPOCH: 9>>> training_loss: 0.017271582281225113\n",
      "FOLD: 0> EPOCH: 9>>> validation_loss: 0.017173669973145362\n",
      "FOLD: 0> EPOCH: 10>>> training_loss: 0.0169291109594976\n",
      "FOLD: 0> EPOCH: 10>>> validation_loss: 0.017004118390057398\n",
      "FOLD: 0> EPOCH: 11>>> training_loss: 0.016468546617629747\n",
      "FOLD: 0> EPOCH: 11>>> validation_loss: 0.01682888491322165\n",
      "FOLD: 0> EPOCH: 12>>> training_loss: 0.01609259536774528\n",
      "FOLD: 0> EPOCH: 12>>> validation_loss: 0.01646154224872589\n",
      "FOLD: 0> EPOCH: 13>>> training_loss: 0.015670125881071695\n",
      "FOLD: 0> EPOCH: 13>>> validation_loss: 0.016405823041239512\n",
      "FOLD: 0> EPOCH: 14>>> training_loss: 0.015413479928301412\n",
      "FOLD: 0> EPOCH: 14>>> validation_loss: 0.016400540684876234\n",
      "FOLD: 1> EPOCH: 0>>> training_loss: 0.21934205309516347\n",
      "FOLD: 1> EPOCH: 0>>> validation_loss: 0.019624629722017308\n",
      "FOLD: 1> EPOCH: 1>>> training_loss: 0.019233085597381322\n",
      "FOLD: 1> EPOCH: 1>>> validation_loss: 0.018496299891368202\n",
      "FOLD: 1> EPOCH: 2>>> training_loss: 0.018104698191758847\n",
      "FOLD: 1> EPOCH: 2>>> validation_loss: 0.01825582786746647\n",
      "FOLD: 1> EPOCH: 3>>> training_loss: 0.01792455349507941\n",
      "FOLD: 1> EPOCH: 3>>> validation_loss: 0.017925553493525672\n",
      "FOLD: 1> EPOCH: 4>>> training_loss: 0.017902072689874204\n",
      "FOLD: 1> EPOCH: 4>>> validation_loss: 0.01784542274215947\n",
      "FOLD: 1> EPOCH: 5>>> training_loss: 0.017856515923669505\n",
      "FOLD: 1> EPOCH: 5>>> validation_loss: 0.017887767493400885\n",
      "FOLD: 1> EPOCH: 6>>> training_loss: 0.01782956671408951\n",
      "FOLD: 1> EPOCH: 6>>> validation_loss: 0.017674128387285316\n",
      "FOLD: 1> EPOCH: 7>>> training_loss: 0.01767263380102976\n",
      "FOLD: 1> EPOCH: 7>>> validation_loss: 0.01744032489216846\n",
      "FOLD: 1> EPOCH: 8>>> training_loss: 0.01752583795597199\n",
      "FOLD: 1> EPOCH: 8>>> validation_loss: 0.017471135828806005\n",
      "FOLD: 1> EPOCH: 9>>> training_loss: 0.017338152340405893\n",
      "FOLD: 1> EPOCH: 9>>> validation_loss: 0.017311251139187293\n",
      "FOLD: 1> EPOCH: 10>>> training_loss: 0.017011438695689475\n",
      "FOLD: 1> EPOCH: 10>>> validation_loss: 0.016974642556970534\n",
      "FOLD: 1> EPOCH: 11>>> training_loss: 0.016557448482604528\n",
      "FOLD: 1> EPOCH: 11>>> validation_loss: 0.016709625607599383\n",
      "FOLD: 1> EPOCH: 12>>> training_loss: 0.0161838825938483\n",
      "FOLD: 1> EPOCH: 12>>> validation_loss: 0.016527956505508527\n",
      "FOLD: 1> EPOCH: 13>>> training_loss: 0.015817197255269668\n",
      "FOLD: 1> EPOCH: 13>>> validation_loss: 0.01643166460258805\n",
      "FOLD: 1> EPOCH: 14>>> training_loss: 0.01558316311103548\n",
      "FOLD: 1> EPOCH: 14>>> validation_loss: 0.016377129405736924\n",
      "FOLD: 2> EPOCH: 0>>> training_loss: 0.21958386233507546\n",
      "FOLD: 2> EPOCH: 0>>> validation_loss: 0.019972299833012665\n",
      "FOLD: 2> EPOCH: 1>>> training_loss: 0.019250208373673618\n",
      "FOLD: 2> EPOCH: 1>>> validation_loss: 0.018394408690864627\n",
      "FOLD: 2> EPOCH: 2>>> training_loss: 0.01816932274248272\n",
      "FOLD: 2> EPOCH: 2>>> validation_loss: 0.017732043483335038\n",
      "FOLD: 2> EPOCH: 3>>> training_loss: 0.017910432770002357\n",
      "FOLD: 2> EPOCH: 3>>> validation_loss: 0.017841520605851775\n",
      "FOLD: 2> EPOCH: 4>>> training_loss: 0.01798885790671844\n",
      "FOLD: 2> EPOCH: 4>>> validation_loss: 0.01784432004813267\n",
      "FOLD: 2> EPOCH: 5>>> training_loss: 0.018013966774088067\n",
      "FOLD: 2> EPOCH: 5>>> validation_loss: 0.017730359886975394\n",
      "FOLD: 2> EPOCH: 6>>> training_loss: 0.01786304819173948\n",
      "FOLD: 2> EPOCH: 6>>> validation_loss: 0.017437460224913513\n",
      "FOLD: 2> EPOCH: 7>>> training_loss: 0.017710901886289817\n",
      "FOLD: 2> EPOCH: 7>>> validation_loss: 0.017432569963452608\n",
      "FOLD: 2> EPOCH: 8>>> training_loss: 0.017609727410314906\n",
      "FOLD: 2> EPOCH: 8>>> validation_loss: 0.017427707609275114\n",
      "FOLD: 2> EPOCH: 9>>> training_loss: 0.017423871481652864\n",
      "FOLD: 2> EPOCH: 9>>> validation_loss: 0.01721639859935512\n",
      "FOLD: 2> EPOCH: 10>>> training_loss: 0.0170545495688655\n",
      "FOLD: 2> EPOCH: 10>>> validation_loss: 0.01680418574453696\n",
      "FOLD: 2> EPOCH: 11>>> training_loss: 0.01665241021955768\n",
      "FOLD: 2> EPOCH: 11>>> validation_loss: 0.01654776910562878\n",
      "FOLD: 2> EPOCH: 12>>> training_loss: 0.016221660986445095\n",
      "FOLD: 2> EPOCH: 12>>> validation_loss: 0.01634012415357258\n",
      "FOLD: 2> EPOCH: 13>>> training_loss: 0.01584852556393006\n",
      "FOLD: 2> EPOCH: 13>>> validation_loss: 0.016212097830746484\n",
      "FOLD: 2> EPOCH: 14>>> training_loss: 0.015554520996962572\n",
      "FOLD: 2> EPOCH: 14>>> validation_loss: 0.016224722135002197\n",
      " The Cross validation loss is :>>  0.014994091669228132\n"
     ]
    }
   ],
   "source": [
    "# setting a standard seed number\n",
    "SEED = [55]\n",
    "# general out of fold array shape\n",
    "out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "# general predictions array shape\n",
    "predictions = np.zeros((len(test), len(target_columns)))\n",
    "\n",
    "for seed in SEED:\n",
    "    out_of_fold_, predictions_ = run_k_fold(number_of_folds, seed)\n",
    "    out_of_fold += out_of_fold_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_columns] = out_of_fold\n",
    "test[target_columns] = predictions\n",
    "\n",
    "valid_results = training_targets_scored.drop(columns=target_columns).merge(train[['sig_id']+target_columns], on='sig_id', how='left').fillna(0)\n",
    "# Given true values\n",
    "y_true = training_targets_scored[target_columns].values\n",
    "# Predicted values\n",
    "y_pred = valid_results[target_columns].values\n",
    "score = 0\n",
    "\n",
    "for i in range(len(target_columns)):\n",
    "    score_target = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_target / target.shape[1]  \n",
    "    \n",
    "print(\" The Cross validation loss is :>> \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Validation loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ef8cf0c40>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2eb25d36a0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Best recorded loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ef82f2f10>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD7CAYAAABqvuNzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5iklEQVR4nO3deXxU1fn48c8zSzaWBEIQISAgiyIIKEvd2ira4orWldavWm3120prF3/WLtrWaqvf2mpbt1K1WlorSmvFatW2olZUJOwiS8OiBFQChLBkm8k8vz/mThiGSeYmmcwkuc/79cqLmTtnJudeJve5zznnniOqijHGGOPLdgWMMcZ0DhYQjDHGABYQjDHGOCwgGGOMASwgGGOMcVhAMMYYA7gMCCIyXUTWiUi5iNyc5PVcEZnrvL5IRIY6288QkSUissr597Qk750vIu+2e0+MMca0S8qAICJ+4H7gTGAMMFNExiQUuwaoUtURwD3AXc72HcC5qjoOuBKYk/DZnwP2tWsPjDHGpEXARZkpQLmqbgQQkSeBGcB7cWVmAD9yHs8D7hMRUdVlcWVWA/kikquq9SLSE/gWcC3wlJvK9uvXT4cOHeqmqDHGGMeSJUt2qGpJqnJuAsIgYEvc8wpganNlVDUsItVAMdEMIeZCYKmq1jvPfwL8Aqhp6ZeLyLVEgwZDhgyhrKzMRZWNMcbEiMj7bsplpFNZRI4h2ox0nfN8AnCkqj6T6r2qOltVJ6nqpJKSlAHOGGNMG7kJCFuBwXHPS51tScuISAAoBHY6z0uBZ4ArVHWDU/4EYJKIbAbeAEaJyKtt2wVjjDHp4CYgLAZGisgwEckBLgPmJ5SZT7TTGOAi4BVVVREpAp4HblbVhbHCqvqgqg5U1aHAycB6Vf10u/bEGGNMu6QMCKoaBmYBLwFrgKdUdbWI3CYi5znFHgGKRaScaEdxbGjqLGAEcKuILHd++qd9L4wxxrSbdKXprydNmqTWqWyMMa0jIktUdVKqcnansjHGGMACgjHGGIcnAsLjb27muRXbsl2NLmNlxW5WbNmd7WoYYzLMEwHhiUUf8PeVFhDc+tkLa7nj+TXZroYxJsPc3Knc5eXn+KlpaMx2NbqMmoYwDY1dZ7CBMSY9vBEQgn5qLSC4Vh+OUBey42WM13iiyajAMoRWqQ9H7HgZ40GeCAj5OX5q7YrXtbpQo2VUxniQJwJCNEMIZ7saXUZ9OGIB1BgP8khACNgVbyvUhRoJR5SGcCTbVTHGZJAnAoI1GbVOvRMILIga4y2eCAgFQT+hRiXUaFe8qYQbIzRGokNOa0LWzGaMl3giIOTn+AFs5IwLdXHNRHa8jPEWTwUEawJJrT6uac2OlzHe4omAUNCUIVgTSCqWIRjjXZ4ICPnB6A3ZdoJLLT5DsABqjLd4IiDEMgQbaZRaXehAhmBNRsZ4i7cCgp3gUqoPx/UhWAA1xlNcBQQRmS4i60SkXERuTvJ6rojMdV5fJCJDne1niMgSEVnl/Hta3HteFJEVIrJaRB4SEX/a9iqBjTJyr976EIzxrJQBwTlR3w+cCYwBZorImIRi1wBVqjoCuAe4y9m+AzhXVccBVwJz4t5ziaqOB8YCJcDF7dmRlhTkRPsQam1cfUp1NsrIGM9ykyFMAcpVdaOqNgBPAjMSyswAHncezwOmiYio6jJVja1MsxrIF5FcAFXd42wPADlAh03AX2AZgmuWIRjjXW4CwiBgS9zzCmdb0jKqGgaqgeKEMhcCS1W1PrZBRF4CtgN7iQaSQ4jItSJSJiJllZWVLqp7KLsPwb34DMHuVDbGWzLSqSwixxBtRroufruqfhY4HMgFTkvyVlR1tqpOUtVJJSUlbfr9+UHLENyKzxAsgBrjLW4CwlZgcNzzUmdb0jIiEgAKgZ3O81LgGeAKVd2Q+OGqWgc8y6HNUGkT9PsI+sUCggux+xBy/D47XsZ4jJuAsBgYKSLDRCQHuAyYn1BmPtFOY4CLgFdUVUWkCHgeuFlVF8YKi0hPETnceRwAzgbWtmtPUoguo2lNIKnEMoSigqBlCMZ4TMo1lVU1LCKzgJcAP/Coqq4WkduAMlWdDzwCzBGRcmAX0aABMAsYAdwqIrc62z4DCDDf6WD2AQuAh9K4X4coyAnYuHoXYgGhT0GOHS9jPCZlQABQ1ReAFxK23Rr3uI4kw0ZV9Xbg9mY+drL7arafravsTl2oEREozA/a1BXGeIwn7lQGZ5EcCwgp1Ycj5AZ8dryM8SDPBATLENypCzWSG/Db8TLGgzwTEPJzAtRYm3hK9aEIecFohmABwRhv8U5ACPpslJELdeEDGYJ1KhvjLZ4JCAU5AbvidSGWIUSPlwVQY7zEMwHBOkndqXcyhPygn7pQhEikw6aYMsZ0Mp4JCAVBawJxoy4UHWVkiwoZ4z3eCQhOm7iqXfG2pD7cSF7Qf2BCQAsIxniGZwJCfk4A1YOXiDSHimUIsQkBrZnNGO/wTEA4sCaCdZS2JJYhxBYVso54Y7zDMwHBltF0J7EPwQKoMd7hnYAQtDZxN+rDEXLj+xAsgBrjGZ4JCLaMpjvRYac+O17GeJBnAkK+NYG4Uh+KkBuMCwiWURnjGZ4JCLFO0jo7wTUrElEaGiPkBfzkO8fLpvswxjs8FBCsCSSV2OI4uUEbdmqMF3kmIMROcBYQmlcfjh6bPGdyO7AmI2O8xFVAEJHpIrJORMpF5OYkr+eKyFzn9UUiMtTZfoaILBGRVc6/pznbC0TkeRFZKyKrReTOtO5VEgU2aial+AwhN+BDxI6XMV6SMiCIiB+4HzgTGAPMFJExCcWuAapUdQRwD3CXs30HcK6qjgOuBObEveduVT0KmAicJCJntmtPUrAbrVKL9a/kBfyICAVBWxPBGC9xkyFMAcpVdaOqNgBPAjMSyswAHncezwOmiYio6jJV3eZsXw3ki0iuqtao6gIA5zOXAqXt3ZmW5AWju2qdpM2LzxDAWVTIAoIxnuEmIAwCtsQ9r3C2JS2jqmGgGihOKHMhsFRV6+M3ikgRcC7w72S/XESuFZEyESmrrKx0Ud3kRIR8u+JtUSxDyA1Em9cKcvwWQI3xkIx0KovIMUSbka5L2B4A/gz8WlU3Jnuvqs5W1UmqOqmkpKRd9SjI8VsnaQtiGUIsm7J1lY3xFjcBYSswOO55qbMtaRnnJF8I7HSelwLPAFeo6oaE980G/quq97a65m2Qn+Onzk5wzUrMEPJtGU1jPMVNQFgMjBSRYSKSA1wGzE8oM59opzHARcArqqpOc9DzwM2qujD+DSJyO9HA8Y22V7917Iq3ZfWhQzMEG2VkjHekDAhOn8As4CVgDfCUqq4WkdtE5Dyn2CNAsYiUA98CYkNTZwEjgFtFZLnz09/JGr5PdNTSUmf7l9K7a4fKzwlYk1ELmjqVYxmC9bkY4ykBN4VU9QXghYRtt8Y9rgMuTvK+24Hbm/lYcV/N9CgIWidpS5qGncaNMrImI2O8wzN3KoM1GaWSmCFE70OwAGqMV3gqIORbm3iLDnQqxzIEC6DGeIm3AoK1ibfowLDT+PsQ7HgZ4xWeCgjRJiNrAmlOYoZQkOMnHFEanEBhjOnePBUQ8nMC1IXs5Nac+nCEHL8Pny/a339gTQTLEozxAk8FhIIcPw2NEcKNFhSSiS2fGXNgCmzLqozxAs8FBLA5/ptTF4qQ6/QfALZIjjEe46mAkG9rIrQoMUPIt1XmjPEUTwUEW0azZfWhSNPU1xC3qJBlVMZ4gqcCQn4wtkiOtYknUx9uJC9woMnIAqgx3uKpgGDLaLasLiFDiAVQm+7DGG/wVEDItyaQFlmGYIy3eSsgBO0E15L6cPI+BDtexniDpwKCNRm1rC50cIZgo7KM8RaPBYRYp7Kd4JJJzBCa7kOwJjZjPMFTAeHAuHrrJE2mLnTwfQgBv48cv88CqDEe4amAYE1GLasPR5pmOo2JThluAdQYL/BUQAj6fQT9YlNXNCMxQwBbVMgYL3EVEERkuoisE5FyEbk5yeu5IjLXeX2RiAx1tp8hIktEZJXz72lx77lDRLaIyL607Y0L+UGb4z8ZVW02Q7AAaow3pAwIIuIH7gfOBMYAM0VkTEKxa4AqVR0B3APc5WzfAZyrquOAK4E5ce95DpjSvuq3nq2allyoUVElaYZgx8sYb3CTIUwBylV1o6o2AE8CMxLKzAAedx7PA6aJiKjqMlXd5mxfDeSLSC6Aqr6tqh+2fxdapyAnYFe8SdSFo8ckMUMoCAasE94Yj3ATEAYBW+KeVzjbkpZR1TBQDRQnlLkQWKqq9a2poIhcKyJlIlJWWVnZmrcmFW0yshNconpn4aDEDMEyKmO8IyOdyiJyDNFmpOta+15Vna2qk1R1UklJSbvrYp2kyR1YPjOhD8HWoTbGM9wEhK3A4Ljnpc62pGVEJAAUAjud56XAM8AVqrqhvRVur3wLCEnVO+smx9+YBk4fgjWxGeMJbgLCYmCkiAwTkRzgMmB+Qpn5RDuNAS4CXlFVFZEi4HngZlVdmKY6t4t1kibXbIZgx8sYz0gZEJw+gVnAS8Aa4ClVXS0it4nIeU6xR4BiESkHvgXEhqbOAkYAt4rIcuenP4CI/J+IVAAFIlIhIj9K6541I9qpbH0IiWIZQl6SDMEyKmO8IeCmkKq+ALyQsO3WuMd1wMVJ3nc7cHszn3kTcFNrKpsOdsWbXH24uQwhQG2okUhE8fkkG1UzxmSIp+5UBrsxrTmxUUbJMgQ4MCzVGNN9eS4gFDh33qpqtqvSqTSXIdiaCMZ4h+cCQn6OH9UDbeYmqi6UfJRR0xTYFhCM6fY8FxAKbNW0pOqbuVM53zIEYzzDewGhaZEcG2kUr+k+hCRzGYEtkmOMF3guINiykMnF7kM4JEMIWgA1xis8FxCskzS55uYyskWFjPEOzwUEaxNPri7ciE8gkHCvgQVQY7zDcwEh1odQZ23iB6kPRRfHETk4IFgTmzHe4bmAkG+jjJKqCx+6fCZYJ7wxXuK5gHCgCcROcPFiGUKipuNlGZUx3Z7nAkK+DaNMqj4cSZoh5AZ8iFiTkTFe4LmAYJ2kydWFGpNmCCJi8z8Z4xGeCwh5AQsIyTSXIcCB+Z+MMd2b5wKCzye2rnISdaHGQya2i7Epw43xBs8FBLBFX5KpD0cOmdgupiAYsE54YzzAkwEh39YJPkSqDMECqDHdn6uAICLTRWSdiJSLyM1JXs8VkbnO64tEZKiz/QwRWSIiq5x/T4t7z/HO9nIR+bUk3hHVgayT9FAN4cghi+PE2DrUxnhDyoAgIn7gfuBMYAwwU0TGJBS7BqhS1RHAPcBdzvYdwLmqOg64EpgT954HgS8DI52f6e3Yj1axJqNDRTuVk2cIdryM8QY3GcIUoFxVN6pqA/AkMCOhzAzgcefxPGCaiIiqLlPVbc721UC+k00cDvRW1bc1unTZH4Dz27szblkn6aGiw06Tfx3ygtbEZowXuAkIg4Atcc8rnG1Jy6hqGKgGihPKXAgsVdV6p3xFis8EQESuFZEyESmrrKx0Ud3UCnIC1ISskzRe6gzBjpfpWOHGCL9fuMnmGcuijHQqi8gxRJuRrmvte1V1tqpOUtVJJSUlaamPdZIeqi7U2Pwoo5yAZVSmwy3bspsfP/ce/1rzcbar4lluAsJWYHDc81JnW9IyIhIACoGdzvNS4BngClXdEFe+NMVndpgC61Q+SLgxQjiiTTftJbJRWSYTqvY3ALCxcn+Wa+JdbgLCYmCkiAwTkRzgMmB+Qpn5RDuNAS4CXlFVFZEi4HngZlVdGCusqh8Ce0TkE87ooiuAZ9u3K+5ZJ+nBmpbPbPY+BD+hRiXUGMlktYzHVNeGANi0wwJCtqQMCE6fwCzgJWAN8JSqrhaR20TkPKfYI0CxiJQD3wJiQ1NnASOAW0VkufPT33ntq8DDQDmwAfhHunYqlfycgF3xxokFhLxmpq6wRYVMJsQCwsbKfVmuiXcF3BRS1ReAFxK23Rr3uA64OMn7bgdub+Yzy4CxralsuhTk+GkIR2iMKH5fxm5/6LTqw9ETfW6Sye3gwJoItQ2NFOYHM1Yv4y17mgLCflT1kMWaTMfz5p3KQVsTIV6ds55ySzemgR0v07FiGcLe+jCV++qzXBtv8mZAsGUhD9KUITTTqZxnq8yZDIgFBLCO5WzxZECwNREOFssQWpr+GmxRIdOxqmtD9CmINklax3J2WEAw1Dsn+mQL5EBcQLDjldTOffV8sLMm29Xo8qprQxw1oDe5AZ91LGeJJwNCfqyT1O5WBqAu3HKGYKOMWvbTF9byP48uynY1urzq2hB9egQZ1q+HNRlliScDgmUIB0udIVgAbcmH1bW8v7OG7Xvrsl2VLq26NkxhfpDhJT3YaE1GWeHJgBAbZWRNIFH1KTIEC6At210T7QxdsaU6yzXpulSVPbUheucHGd6vJx/sqrEbIbPAkwHBOkkPVpciQ7BRWS3bXROdcmHFlt3ZrUgXVheK0NAYoSg/h2H9etAYUT7YZf0ymebJgGBt4gdLlSHk27DTFlXFMoSK3dmtSBcWG3IaazICG3qaDZ4MCAXBaJu4neCiYhlCc/chBP0+gn6x45VEXaiR2lAjItEMIRLRbFepSzo4IPQEbAqLbPBkQDjQBGKdpJB6cjuILTtqxytRrP9gfGkRe+rCbNppV7VtER8QCvOD9OuZYxlCFngyIOQEfAR8dsUbU9+UITT/dSjICdjxSqLK6T84dXR0zkbrR2ib+IAAMLxfT7s5LQs8GRDAFsmJF10tzdfiZGIFtiZCUrGAMHloH3rk+C0gtFFiQBjWrwcbd1iTUaZ5NiAU2LrKTWIBoSW2DnVysSajvj1zGFdayHILCG0SG6nVlCGU9GDHvoaD5jcyHc/DAcHWRIipCzU2O+Q0xhYVSi6WIfQpyGH84CLe+3BP02SBxr09tSFEoFdedMCHdSxnh2cDQn7QTnAx9eFIix3KEJ3uo8YC6CFiGUJhfpAJpUWEGpU1H+7Ncq26nuraEL1yA/ic9UliQ0+tHyGzvBsQcvw2FYOjLtTY7JDTmAIbZZRU1f4G8oN+8oJ+JgwpAqxjuS2qa0MUFhxYfGlI3wL8PrGRRhnm2YBgTSAH1IcjzS6OE2PHK7mqmgNTNg/onUf/XrnWj9AG1bWhg1bjC/p9DOlbYB3LGeYqIIjIdBFZJyLlInJzktdzRWSu8/oiERnqbC8WkQUisk9E7kt4z6UislJEVovIXWnZm1aIjqu3ExxEF8hJlSHkWadyUrtrGigqyAFARBg/uMgyhDZIDAgAw23W04xLGRBExA/cD5wJjAFmisiYhGLXAFWqOgK4B4id4OuAW4AbEz6zGPg5ME1VjwEGiMi09uxIa9kV7wF1IRcZgvW5JFVV00CfHgdOZBMGF7Fxx36qa2x0TGskDQglPdi0Y7/d/Z1BbjKEKUC5qm5U1QbgSWBGQpkZwOPO43nANBERVd2vqm8QDQzxhgP/VdVK5/m/gAvbtAdtlG83WjVxkyHE7kNQtT/OeLtrQk0ZAkQDAsDKrbuzU6EuKjb1dbzhJT2pD0fYVl2bpVp5j5uAMAjYEve8wtmWtIyqhoFqoLiFzywHRovIUBEJAOcDg5MVFJFrRaRMRMoqKyuTFWmT6H0I1kkK7jKE2KJCseU2TVRVTUNTHwLAuNJCAJZ/sDtLNep64qe+jje8n01yl2lZ6VRW1SrgK8Bc4D/AZiDp5bqqzlbVSao6qaSkJG11sCveA9xmCAA1FkSbRCLqrAN8IEPonRfkyJIeNvNpK8Smvk7MEIY1zXpqHcuZ4iYgbOXgq/dSZ1vSMs4VfyGws6UPVdXnVHWqqp4ArAPWu610OuTn+InogYndvKwu5O5OZbAZYuPtqQsRUQ5qMgKYMLgPy7dU28WGS4nTVsSU9MylV27AVk/LIDcBYTEwUkSGiUgOcBkwP6HMfOBK5/FFwCua4q9BRPo7//YBvgo83JqKt1eBrZrWpN7lncpgiwrFi62DEN9kBDBhcCE79tWzdbe1fbvRXEAQkehymtZklDGBVAVUNSwis4CXAD/wqKquFpHbgDJVnQ88AswRkXJgF9GgAYCIbAZ6Azkicj7wGVV9D/iViIx3it2mqhnPEABqQo30yeQv7oTczGVky2geKn7ainjjnY7lFVuqKe1TkOlqdTnNBQSIdiy/s2lXpqvkWSkDAoCqvgC8kLDt1rjHdcDFzbx3aDPbZ7quZQeIdZJ6vWNZVZ2pK1LchxC0PoREsQnZihIyhKMG9CYn4GNFxW7OPvbwbFStS2kxIPTrwTPLtlLb0Nh0EWc6jnfvVLZlIYHUy2fGFDQFUG8fr3hV+2NNRgdnCDkBH8cM7G13LLvUUkAYZnMaZZR3A4I1gQBQ7wwjtT6E1muuyQiiK6itqqgm3GiDFlJpOUNwZj21KSwywrMBId9OcABNUzWnHGVkGdUhdteE8MVN2RxvwuAiakON/He7nchSiQWEXnlJMgTnXoRN1rGcEZ4NCNYEEhW70cxtp7LXj1e8Kmceo9iUzfEOdCzvzmyluqA9tSF65QXwJzmO+Tl+BhXl29DTDPFwQLArXjiQIaRuMooGUK8fr3jRaSsOvaoFGFpcQGF+0G5QcyHZPEbxokNPLdPKBM8GhKYmI4+PmnHbqZwX9CFixytedNqKQ/sP4MDMp8tsCouUUgWEYc6sp3ajX8fzbkCwNnEgujgOpM4QRMRWmUsQvxZCMhNKC1n/8V7211sQbUnKDKFfD/bWh6ncV5/BWnmTBQSPn+DcZgjgLDvq8U74ePFrISRzwpH9iCh875lVNNoUzs1K3WQUHWlkHcsdz7MBwecT8oI+z48ycpshgLPsqMcDaLzEmU4TnXBkMTdNH82zy7fx7aeWW1BoRnVt830xcGB9ZetY7niu7lTurgpyAp6/87YpQ0gx/TXEFhXy9vGKqQs1UheKtJghAHz10yNQhZ+/tA6fCD+/eHzS0TReVp1k6ut4AwvzyQ342GBDeDucpwNCdBlNb984FMsQUk1/DdHpPmptPQSg5ZvSEl1/6ghUlbtfXg8CP7/IgkJMXaiRhvChU1/H8/mE8aVFvLq+ku+rImLHrqN4tskIYmsiePuKN5YhpFogB6LTfdgoo6gD01Y0fyKLN+u0kXz7jFH8delWbpq30pqPHC3dpRxvxsSBlG/fx+ptezJRLc/yfEDwfKdyKzIEO14HHJjYLnWGEPO1aSP55umj+MvSCm7+y0pbKxj3AeHscYeT4/fxzLLEpVhMOnk6IOTbCY66VmQI1ql8QNNaCD3cZQgxN5w+khumjeTpJRXc+eLajqhal+I2IBQV5HDqUSXMX7HN5ofqQJ4OCAU5Ac+f4GKT2+X43XYqe/t4xbSmDyHRN88YxRemDmH26xt5dd32dFetS6mucRcQAC6YOIjKvfUs3NDiYoymHTwdEKI3Wnm7Tbwu3EjAJwRcBAQ7Xgc0txaCW7ecM4bRh/XixqdXULnXuzdcuc0QAE49qj+98wL8zZqNOoy3A4I1gVAfiri6BwFio4y8fbxiqmpCFOT4XfW9JJMX9PPrmRPZWxfmxqdXeLY/YXcrAkJuwM/Zxw7kxXc/sru/O4irgCAi00VknYiUi8jNSV7PFZG5zuuLRGSos71YRBaIyD4RuS/hPTNFZJWIrBSRF0WkX1r2qBUKcuzO27pwo6u7lCF6vEKNSsjacFucx8it0QN68YNzxvDa+koeXbgpTTXrWlqa+jqZCyYOojbUyMvvfdSR1fKslGcCEfED9wNnAmOAmSIyJqHYNUCVqo4A7gHucrbXAbcANyZ8ZgD4FXCqqh4LrARmtWM/2sQyhNZlCLZIzgEtzXTaGpdPHcJnxhzGXS+u5d2t1WmoWdfS0tTXyUw6og+lffL561JrNuoIbi4NpwDlqrpRVRuAJ4EZCWVmAI87j+cB00REVHW/qr5BNDDEE+enh0TvMukNbGvrTrRVvx651Icjnu7Yq29FhlDcM3pF/NK7dnWWjgwBopMG3nXhsRT3yOXrf17muaaQVPMYJfL5hPMnDGJh+Q6270k8rZj2cnMmGARsiXte4WxLWkZVw0A1UNzcB6pqCPgKsIpoIBgDPOK61mny+alDOGZgb67/01Le8+gNL3WhCLkuM4Szxw3khOHFfO+ZVbzl8ZEe6coQAPr0yOGeSyewaed+fjR/dVo+s6tobUAAOH/iICIK81dk/Bqy28tKp7KIBIkGhInAQKJNRt9tpuy1IlImImWVlZVprUeP3ACPXjWZ3vlBrn5sMR9Ve++KozUZQk7Ax0P/czxHFPfgujlllG/f28G167zSlSHEnHBkMdd/egRPL6lg3pIKz8z935aAMKJ/T44tLbSb1DqAmzPBVmBw3PNSZ1vSMk7/QCHQ0iXkBABV3aDRb/5TwInJCqrqbFWdpKqTSkpKXFS3dQ7rncejV01mX32YLz62mH0eS9nrQxHXAQGio0F+f9VkcgI+vvjYYnZ4cI76xohSXdvyWghtccPpIzluSBE3Pr2C037xGne/tI73tu3p1sGhLQEB4PwJg1i9bQ/rP/buRUlHcHMmWAyMFJFhIpIDXAbMTygzH7jSeXwR8Iq2/C3eCowRkdgZ/gxgjftqp9fRh/fm/i8cx/qP9zLriaWeuhOyPtzoulM5ZnDfAh6+cjKVe+v50uNlTRPkecWe2hCqrZu2wo2g38cfrpnKTy8Yx6CifB54tZyzfv0fpv3iNX7x8jrWfdT9Tn5tDQjnjh+I3yeWJaRZyoDg9AnMAl4ietJ+SlVXi8htInKeU+wRoFhEyoFvAU1DU0VkM/BL4CoRqRCRMaq6Dfgx8LqIrCSaMfw0fbvVep8aVcJPZozl1XWV/Oi51d36qixefbh1GULMhMFF3HvpRFZU7Oabc5d7ahx9013KrZy2wo2euQE+P3UIf/zSVN75/uncccFYBhTmcf+Ccj577+vc+uy73SoAtzUglPTK5ZSR/Xh22VZPffc6mqvpr1X1BeCFhG23xj2uAy5u5r1Dm9n+EPCQ24pmwuenDuH9Xfv57WsbOaJvD778yeHZrlKHqwu1PkOImT52AN8/62huf34Nd764lu+ddXSaa9c5xeYxSneGkKhfz1y+MPUIvjD1CCr31vPgqxt4dOEm3t64k1/PnMhRA3p36O/vaLGpr1taC6ElF0wcxA1PLmfRpl2ccGSzY1hMK3h6PYRkvvPZo6jYVctP/7GGl9/7iPGlRYwfXMT40iIG983vdnOxtzVDiLnm5GF8sKuG2a9vZNGmXUwcXMT4wYUcW1rEsOIe+LrhvP+72zGPUVuV9Mrl1nPH8MlR/bjx6ZWcd99CvnvmUVx14tAu+51szbQVyXxmzAB65Ph5cvEHDCrKRyQ6LNUnIETXAC9Mcz9Pd2cBIYHPJ/zikvEMKS7gnU27mPP2+zz8RvQu0j4FQY4tLeKyyYM5c9zhWa5perQnQ4DoOPpbzxlDSc9c3ijfwVNlW3jszc0A9MoLcGxpITMmDOKSSYNb/qAupGmm0yycbD49uj8vfuMUbpq3kh8/9x6vra/k5xeNp6RXbsbr0l7tDQj5OX6mjz2cvyyt4Nnlhw5B9QncccE4Zk4Z0q56eokFhCTygn6+M/0oAEKNEdZ9tJcVFbtZuaWaRZt28pU/LeX7Zx3dLZqU2pshAAT8Pr42bSRfmzaSxohSvn0fK7bsZkXFbhZv3sVN81aysXI/35k+ustezcZry1oI6dSvZy6PXDmJOW+/z+3Pr+HMX73Ob2Ye1+WaTdobEAC+f/bRnDKyH40RJaKKKihKROG5Fdu45W/vcmRJT6YM65uuandrFhBSCPp9jB1UyNhBhXxhanRUzrfmruCOF9ZQua+em6cf1WWbRVSVulCjq/WU3fL7hNEDejF6QC8umTyYxojyw/nv8tBrG9ixr547PzfO1cyqnVlVTQN+n9A7L3t/PiLCFScMZeqwYq5/YilX/f4dZl8xiU+NSv/Q7I7Smqmvm9O3Rw7nT0y8TzbqrLGHc/4DC/nKH5fw7KyTKO1T0Obf4xVd+y8zC3ID0VkqrzjhCGa/vpEb563ospO9hSPRK6m8Ns7Y6YbfJ/xkxli+efoo5i2p4Lo5S7r8/FFVNSGK8oOdItsZPaAXT113AkeW9OTLj5fxytqPs10l19KRIbSksCDI766YREM4wrV/WGJTt7tgAaEN/D7hx+cd07RG7rV/KOuSX7bYesrpzBCSERFuOH0kd1wwlgXrtnP5I4uaml26ot01DWmbtiId+vbI4YkvT2X0gF5cN2cJL6/uGnNNdXRAgOhdzb+eOZE1H+3h/z290jPDydvKAkIbiQhfmzaSn31uHK+tr+QLDy+ian/XOsnFxrO3p1O5Nb4w9Qge+MJxrKqo5uKH3uLD6tqM/N50q9ofyugIIzeKCnL445emcszAQr76p6W8sOrDbFcppVhAaOuwU7dOPao/35l+FM+v+pD7F5R36O/q6iwgtNPMKUN48PLjWb1tD+c/sJBnllV0mSakpgyhnZ3KrTF97OE8fvUUPqqu4/z7F/LEog+63I1WVTUNWetQbklhfpA510xhwuAivvbnZZ1+8rfq2hC9ct1Pfd0e131yOOdPGMjdL6/nn+91nWa1TLOAkAafPWYAf/rSVHIDPr45dwWf/vmrPLZwU6dvK890hhBzwpHFzL3uBA7rncf3nlnFyXct4IFXy9lTF8poPdpqd0365zFKl155QR6/egrHH9GHbzy5jCff+aDTNpPsqQ11eHYQIyLceeGxHFtayDeeXMYzyyr495qPeW19JW+W7+CdTbtY+kEVqyqqWfvRHsq37+P9nfvZuruW7Xvq2NtFvpvtZaOM0mTy0L68eMMnWbBuOw++uoEfPfcev/r3f7nyxKFcecJQ+vTofFeU9aHMZwgxYwb25tnrT+KtDTt58LUN/N+L63hwwQY+/4khXHPSMPr3zst4ndyqqmnolP+fMT1yAzz2xclc+4cl3PzXVTxVtoXvnnU0k4d2rqGXbZ22oq3ygn5++z/HM+O+hXxz7opWvVcEvnbqCL55xqhOMZigo1hASCOfT5h29GFMO/owFm/exUOvbuDef/2X3762kZ+cP5aLji/NdhUPUheOZghtXRe4vUSEE0f048QR/Xh3azUPvbaB372+kd+/sZmbpo/mmpOHdbo/vtqGRurDkU7VqZxMQU40KMxbUsE9/1rPxQ+9xelH9+em6Ucx6rBe2a4eEA0ImT6Ohxfm8+9vf4otu2oJRyKEGiOEGpVwoxKKRAiFI4Qj0WViw41KOBKhoVF5Z9Mufv1KOduq6/jZ58YR7OJDp5tjAaGDTB7al8lX9WXdR3v50fzV3Pj0CrZW1fL1aSM6zUmuKUPo4FFGbowdVMh9nz+O93fu547n13D782uoqKrllnPGZKSN2a3YxHZF+Z03Q4gJ+H1cNmUIMyYM4tGFm3jo1Q1Mv/d1LjyulG+eMYqBRflZrV91bYgR/Xtm/Pf2ygsyZmDrAtHlU4cwvF8PfvXv//LxnjoevPx4euZ2v9Nn9s8E3dzoAb14/OopfO64Qdzzr/V85y8rO02nc32WM4RkjijuwUOXH8+XTxnGY29u5it/7Fz3LTTNdNrJM4R4+Tl+rj91BK/fdCpXnzSMZ5dv49S7X2XJ+7uyWq9MNxm1h4jwzTNGcdeF43hzw04u/e1b3XIJTwsIGZAT8PGLi8fz9WkjeaqsgqsfW9wpOqnqnAwhrxNkCPF8PuH7Z4/hR+eO4Z9rPmbm795mZydZiGd3hmY67Qh9euTwg3PG8MqNn6J/71xueHJ5Vr+HXSkgxFw6eQgPXzmJTTv2c8EDb3a7VQM715mgGxMRvnXGKP7vwmN5c8NOLvnt21lfsrMzZgjxrjppGA9dfjxrPtzD5x58k42V+7JdpQ5dCyFTSvsUcO+lE/mwuo4fPpudNZzrQtG+mEyNMkqnU0f3Z+61J1AfjnDhg2+x5P2qbFcpbSwgZNglkwfz6FWT+WDnfi54YCFrPtyTtbrUd9IMId5njxnAn6/9BHvrwlz44JuUbc5uM8eBmU67XoYQ7/gj+vC100bw12VbeXZ55lcd25OBu5Q70rjSQp756okUFQT5+p+Xdbl7aZrTec8E3dinRpXw1P+eQESV8+9fyJy3NmdlrHhnzxBijhvSh79+5USKCnK4bPbb3PfKf2nM0ipZu/fHZjrtmieyeLNOHcFxQ4r4wd/epaKqJqO/OxPTVnS0wX0LuOvCY9m6u5bZr2/MdnXSwgJClhwzsJDnvnYyU4cXc8uzq7nm8TIq92a2nbyuE40ySmVovx787asnMX3sAO5+eT0zZ7+d8ZMYRDOEghx/pw+ibgT8Pu69dCKq8K25KzIaZLtDQAD4xPBizh53OA+8Ws623V1zKpZ4rs4EIjJdRNaJSLmI3Jzk9VwRmeu8vkhEhjrbi0VkgYjsE5H74sr3EpHlcT87ROTedO1UV9G/Vx6PXTWZH547hjfKd3Dmr15nwdrtGfv9sQyhI2c7TafCgiC/mTmRX14ynvc+3MOZ9/4n480du2saunxzUbwhxQX8+LxjeGfzLh56bUPGfm93CQgA3z3rKFThZ/9Ym+2qtFvKgCAifuB+4ExgDDBTRMYkFLsGqFLVEcA9wF3O9jrgFuDG+MKquldVJ8R+gPeBv7ZnR7oqn0/44knDeG7WyfTrmcsXH1ucsYXU68MRRCDo7zzj/FMRET53XCn/uOEURg3oxQ1PLueGJ5dlbNqLqk4202k6fO64QZxz7OHc88/1rNiyOyO/szsFhNI+BVz3qSN5bsU23tmU3T6u9nKTIUwBylV1o6o2AE8CMxLKzAAedx7PA6aJiKjqflV9g2hgSEpERgH9gf+0uvbdyOgBvfjb9SdxzcnD+MNb73Pub95g7Ucd2+FcF2okL+DvNDfKtcbgvgXMvfYTfPP0Ufx95Yecee9/MjKuvqqm88102l4iwh3nj6N/r1y+MXc5++s7fir33WlYHKcz+d9PDefwwjx+/NzqrPVvpYObgDAI2BL3vMLZlrSMqoaBasDten6XAXO1mV5VEblWRMpEpKyystLlR3ZNeUE/t5wzhjnXTGF3bYgZ9y1kztvvd1iHc3040iX6D5oT8Pu44fSRPP2/J+DzwSW/fZv7F5R36B9kZ1sLIV0KC4L88tIJbN65n5v+spJIB5/UMjX1daYU5AT47llHs3rbHp4u25L6DZ1UZzgbXAb8ubkXVXW2qk5S1UklJV1necD2OGVkCf+44ZRoh/Pf3uUrf1zatNxgOsUyhK7uuCF9eP7rp3Dm2AH8/KV1XPHoog67i7Q7ZggxnxhezM3Tj+L5lR/yk+ff69CRb5mc+jpTzj32cCYP7cPPX1rXFPC6GjcBYSswOO55qbMtaRkRCQCFwM5UHywi44GAqi5xVVsP6dczl8eumsz3zjqKf635mLN+nf4mka6eIcTrnRftcL7rwnEseb+KM3/1H15dl94O+saIsqeu8059nQ7XfnI4V580jN8v3MxDr3XcUMpMTn2dKSLCD889hl01Dfzm3//NdnXaxM3ZYDEwUkSGiUgO0Sv6+Qll5gNXOo8vAl5prgkowUxayA68zucTrv3kkcz7yokHNYmkK52vCzVmZerrjiIiXDp5CM/NOpmSXrlc9fvF/PSFNTSE0zN3VHVtCNWuOW2FWyLCD84+mvPGD+SuF9cyb0lFh/yerjhthRtjBxVy6aTBPPbmZsq3Z//O+tZKeTZw+gRmAS8Ba4CnVHW1iNwmIuc5xR4BikWkHPgW0DQ0VUQ2A78ErhKRioQRSpdgASGlCYOLDmoS+fUr6bn6qA9HMr44TiaMPCzaQX/5J4Yw+/WN3Pb39EzP0B2mrXDD5xPuvng8J4/ox3f+spJX1qZ/hbHuGhAAbvzsaPKDfm77e8c2u3UEV5eHqvqCqo5S1SNV9Q5n262qOt95XKeqF6vqCFWdoqob4947VFX7qmpPVS1V1ffiXhuuql1/8G4GxJpEZkwYyP0LytMyAqk+FOlWGUK8vKCf288fx5dOHsYf3/6AtzakbMFMaXds6utunCHE5AR8PPQ/x3P04b346p+WsvSD9M7X050DQr+euXz7M6N4fX0ldzy/pksFhe55NuimYm2UvfOCfGfeSsLtnEa7LtzYLTOEeN/+zGiG9C3gu39d2e5ptKv2d495jNzqmRvg91dN4bDeeVz92OK0NoF054AAcOWJQ7nqxKE8/MYm7nulPNvVcc0CQhfTt0cOPzrvGFZUVPPowk3t+qzunCHE5Of4ufPCcWzeWcM9/1rfrs/qimshtFdJr1z+cPUUAj7h8797O22TC1bXhijsxsdRRLj1nDF8buIgfvHP9fzhrc3ZrpIr3fts0E2dc+zhnH70Yfzi5fVs3rG/zZ9TF24kt5tnCAAnHtmPmVOG8PB/NrbrTtyuvBZCexxR3IM/fmkq+Tl+Lp39Nr97fWO7mkFiU1935wwBon0xd110LKcffRi3Pruavy3L/KyyrWUBoQsSEe64YCw5AR/facdNRF7IEGK+e9ZR9O+Vx03zVrZ51FFVTQN+n9A7r/stnZjKUQN689zXTuaMow/jjhfWcO2cJW0ea7+nm92U1pKg38d9n5/ICcOL+fbTK/jXe+nvoE8nb5wNuqHDeufxg7OPZtGmXTzxzgdt+oz6cGO3mLXTjd55Qe64YCzrPt7LA6+2rU23qiZEUX6wS071kQ6984I8ePlx3HLOGBas3c45v/kPqyqqW/053WkeIzfygn5+d+UkjhnYm+ufWMrbG9s/wKGjWEDowi6ZNJiTRhRz5z/Wtmnq3fpQpFMvjpNu044+rGmU1rqPWr/0YXedtqI1RIRrTh7G3OtOINyoXPjgm8x5a3OrslSvBQSIdtA/9sUpDOlbwJceL8v6Qk/N8c7ZoBsSEe783LE0RpTvP7Oq1e269eGIZzKEmB+eewy98oLcNG9Fq0dpVXWzqa/b4/gjotOFnDgiup7Hp+9+lQdeLXe1pocXAwJEB4TMuWYqJb1y+fzDi/j7ym3ZrtIhLCB0cYP7FvD/PjuaBesquX9BOVtdZgqNEaWh0VsZAhw8SuvOf6zl/Z37XQfS3TUhz3Uot6RvjxwevXIyv5k5kYFFefzfi+s48c5/c/2flrKwfEezWYNXAwLAgMI8/vqVExlfWsisJ5bx0GsbOtV9Ct7rHeuGrjxxKP9a8zF3v7yeu19ez8DCPI4f2pfJQ/tw/BF9OGpA70MmEYt1rHotQ4DoJGQvrf6Ih9/YxMNvbKJfz1wmD+3DpKF9mXREH8YM7E3Qf2igrKppYNygwizUuPPy+YRzxw/k3PED2VC5jz8v+oB5Syt4ftWHDC0uYPrYw5l0RB+OO6IPfXtEg6mXAwJAHydT+H/zVnLnP9ayZVcNPz7vGAJJvnOZZgGhG/D7hDnXTGXtR3so21zF4s27WLxpF8+tiKakQb+Q4/cRDPgI+n0EfYLPCRBeGWUUT0T4zWUTuWHaSBZv3sWSzVUsfn8X/3j3IyB6PPMCPgL+6PHK8QsBv4/te+vp08MyhOYcWdKTH5wzhhs/O5p/vPshT76zhUfe2MhDr0WvgIf368HxR/Shcl+0WcmLo7Vi8oJ+fnXpBEr75PPgqxvYuruW+z5/HD1zs3tMpDOlK6lMmjRJy8rKsl2NLkFV2bq7lrLNVaz7eC+hcIRQY4SGRiXcGH0M8I3TRzG0X48s17Zz+HhPHWWbq3jvw2rqQ9FjFIpo07GLaHQ20LGWJbhWF2pkZUU1S96vcn52UVUTol/PXMp+cHq2q9cpPLHoA2559l1GH9aLR66axOGF+Wn/HSKyRFUnpSxnAcEYkymqyqYd+/GJ2IVInFfXbef6Py0F4MufHM6XThme1mzBbUDwXnuBMSZrRIThJT0tGCT49Oj+/P3rp/DJUSXc+6//8qn/W8BjCzelbep2tywgGGNMJzCsXw8evPx4/nb9SYw6rBc/eu49pv3yVf62bGuHL2kaYwHBGGM6kQmDi3jiy1N5/Oop9MoN8o25yzn7N2/wcQctCxvPu938xhjTSYkInxpVwikj+vHcym28sOpDSnrmdvjvtYBgjDGdlM8nzJgwiBkTBmXm97kpJCLTRWSdiJSLyM1JXs8VkbnO64tEZKizvVhEFojIPhG5L+E9OSIyW0TWi8haEbkwLXtkjDGmTVJmCCLiB+4HzgAqgMUiMj9+KUzgGqBKVUeIyGXAXcClQB1wCzDW+Yn3fWC7qo4SER/Qt917Y4wxps3cZAhTgHJV3aiqDcCTwIyEMjOAx53H84BpIiKqul9V3yAaGBJdDfwMQFUjqrqjTXtgjDEmLdwEhEHAlrjnFc62pGVUNQxUA8XNfaCIFDkPfyIiS0XkaRE5zG2ljTHGpF+2hp0GgFLgTVU9DngLuDtZQRG5VkTKRKSssrIyk3U0xhhPcRMQtgKD456XOtuSlhGRAFAItLQs0E6gBvir8/xp4LhkBVV1tqpOUtVJJSUlLqprjDGmLdwEhMXASBEZJiI5wGXA/IQy84ErnccXAa9oC5MkOa89B3za2TQNeK+58sYYYzpeylFGqhoWkVnAS4AfeFRVV4vIbUCZqs4HHgHmiEg5sIto0ABARDYDvYEcETkf+IwzQuk7znvuBSqBL6Zzx4wxxrROl5rtVEQqgffb+PZ+gFdHMnl538Hb++/lfQdv73/8vh+hqinb3LtUQGgPESlzM/1rd+TlfQdv77+X9x28vf9t2Xeb3M4YYwxgAcEYY4zDSwFhdrYrkEVe3nfw9v57ed/B2/vf6n33TB+CMcaYlnkpQzDGGNMCCwjGGGMADwSEVGs5dDci8qiIbBeRd+O29RWRf4rIf51/+2Szjh1FRAY762+8JyKrReQGZ7tX9j9PRN4RkRXO/v/Y2T7MWaek3Fm3JCfbde0oIuIXkWUi8nfnuSf2XUQ2i8gqEVkuImXOtlZ/77t1QIhby+FMYAwwU0TGZLdWHe4xYHrCtpuBf6vqSODfzvPuKAx8W1XHAJ8Arnf+v72y//XAaao6HpgATBeRTxBdn+QeVR0BVBFdv6S7ugFYE/fcS/t+qqpOiLv3oNXf+24dEHC3lkO3oqqvE50+JF78ehWPA+dnsk6ZoqofqupS5/FeoieGQXhn/1VV9zlPg86PAqcRXacEuvH+i0gpcDbwsPNc8Mi+N6PV3/vuHhDcrOXgBYep6ofO44+Abr/2hLOM60RgER7af6fJZDmwHfgnsAHY7axTAt37b+Be4CYg4jwvxjv7rsDLIrJERK51trX6e59ycjvTvaiqiki3HmssIj2BvwDfUNU90QvFqO6+/6raCExwFqF6BjgquzXKDBE5h+iSvEtE5NNZrk42nKyqW0WkP/BPEVkb/6Lb7313zxDcrOXgBR+LyOEAzr/bs1yfDiMiQaLB4E+qGltvwzP7H6Oqu4EFwAlAkbNOCXTfv4GTgPOc2ZWfJNpU9Cu8se+o6lbn3+1ELwSm0IbvfXcPCG7WcvCC+PUqrgSezWJdOozTZvwIsEZVfxn3klf2vyS2PK2I5ANnEO1HWUB0nRLopvuvqt9V1VJVHUr07/wVVf0CHth3EekhIr1ij4HPAO/Shu99t79TWUTOItq2GFvL4Y7s1qhjicifiS481A/4GPgh8DfgKWAI0enDL1HVxI7nLk9ETgb+A6ziQDvy94j2I3hh/48l2nnoJ3qx95Sq3iYiw4leNfcFlgGXq2p99mrasZwmoxtV9Rwv7Luzj884TwPAE6p6h4gU08rvfbcPCMYYY9zp7k1GxhhjXLKAYIwxBrCAYIwxxmEBwRhjDGABwRhjjMMCgjHGGMACgjHGGMf/B80waXWWwOn6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
