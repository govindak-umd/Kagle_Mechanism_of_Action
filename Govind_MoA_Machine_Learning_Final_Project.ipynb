{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action (MoA) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some of the important terms used in the headings of the tables are presented here:\n",
    "    \n",
    "    g - : signifies gene expression data\n",
    "    c - : signifies cell expression data\n",
    "    cp_type : indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\n",
    "    NOTE: (samples with control perturbations don't have MoAs)\n",
    "    cp_time - treatment duration (24,48,72) Hours\n",
    "    cp_dose - Dosage - HIGH or LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the multi label stratified k-fold \n",
    "# cross validator\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Initial random imports\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Importing pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device_code = 'cuda'\n",
    "else:\n",
    "    device_code = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the seed, so that every time the seed is started from the same number\n",
    "\n",
    "def set_seed_characteristics(seed=55):\n",
    "    # Setting a random seed value\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    # for guaranteering the reproducability of numbers by setting seed for NumPy\n",
    "    \n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    # for setting the seed for cuda or cpu\n",
    "    \n",
    "    torch.manual_seed(seed) \n",
    "\n",
    "    # To ensure that Pytorch doesnt just switch to the fastest possible algorithm but \n",
    "    # ensures that it selects a deterministic algorithm\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.read_csv('input/train_features.csv')\n",
    "# Reading the head rows and columns of train features\n",
    "training_features_head = training_features.head()\n",
    "\n",
    "training_targets_scored = pd.read_csv('input/train_targets_scored.csv')\n",
    "# Reading the head rows and columns of train targets scored\n",
    "training_targets_scored_head = training_targets_scored.head()\n",
    "\n",
    "testing_features = pd.read_csv('input/test_features.csv')\n",
    "# Reading the head rows and columns of train targets non-scored\n",
    "testing_features_head = testing_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - training features \n",
    "training_features_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - train targets scored \n",
    "training_targets_scored_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303 -0.1193   \n",
       "1 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690 -0.5382   \n",
       "2 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530 -1.0140   \n",
       "3 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325 -0.9005   \n",
       "4 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742  1.0900   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2  0.8662  1.0160  0.4924 -0.1942  \n",
       "3  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4 -0.2962 -0.5313  0.9931  1.8380  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - test features\n",
    "testing_features_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset classes, training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch data loader implementation of MoA dataset\n",
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return train_tensor_dictionary\n",
    "\n",
    "# Pytorch data loader implementation of test dataset\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        test_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return test_tensor_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch model for the MoA determination\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    # Instantiaing all the models before utilizing\n",
    "    # them later in the forward function.\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        \n",
    "        # super keyword used to access data from the parent\n",
    "        # pytorch.nn.Module class\n",
    "        super(Model, self).__init__()\n",
    "        # Applying batch normalization. This is done to standardize\n",
    "        # the input for each mini batches and will help reduce the\n",
    "        # number of epochs for which the training is done. This limits\n",
    "        # the covariate shift (this is the value by which the hidden\n",
    "        # layer values shift around) and allows to learn from a more \n",
    "        # stable set of data. Sometimes, it also allows for a\n",
    "        # higher learning rate.This is also used for regularization\n",
    "        # and helps reduce over fitting. Generally, if batch \n",
    "        # normalization is used, you can use a smaller dropout,\n",
    "        # which in turn means that lesser layers can be lost \n",
    "        # in every step.\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)        \n",
    "        # For regularization purposes the dropout is set\n",
    "        # This is done by setting a probablity. Random \n",
    "        # neural networks are picked at a probablity, say p\n",
    "        # or dropped at a probablity of 1-p. This is essential \n",
    "        # to prevent overfitiing of the model and also reduces\n",
    "        # the computation time. A fully connected neural network, if\n",
    "        # run without dropout will start forming dependancies between\n",
    "        # each other and this can lead to over-fitting.\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        # nn.utils.weight_norm : This is weight normalization. Usually,\n",
    "        #                        faster than batch normalization\n",
    "        # nn.Linear : Applying linear transform to the incoming data\n",
    "        #             and creates a single layer feed forward network.\n",
    "        # input size : num_features\n",
    "        # output size : hidden_size\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        # input size : hidden_size\n",
    "        # output size : hidden_size\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        # input size : hidden_size\n",
    "        # output size : num_targets\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    # The forward function basically defines the model\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def trainingFunction(model, optimizer, scheduler, lossFunction, trainloader, device_code):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for training_data in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = training_data['x'].to(device_code), training_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        training_loss += loss.item()    \n",
    "    training_loss /= len(trainloader) \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate the model\n",
    "def validationFunction(model, lossFunction, validationloader, device_code):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_predictions = []   \n",
    "    for validation_data in validationloader:\n",
    "        inputs, targets = validation_data['x'].to(device_code), validation_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        validation_loss += loss.item()\n",
    "        validation_predictions.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    validation_loss /= len(validationloader)\n",
    "    validation_predictions = np.concatenate(validation_predictions)\n",
    "    return validation_loss, validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the inference function\n",
    "def inferenceFunction(model, inferenceloader, device_code):\n",
    "    model.eval()\n",
    "    inferences = [] \n",
    "    for data in inferenceloader:\n",
    "        inputs = data['x'].to(device_code)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        inferences.append(outputs.sigmoid().detach().cpu().numpy())   \n",
    "    inferences = np.concatenate(inferences)  \n",
    "    return inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dummy inserts to the cp_time and cp_dose columns\n",
    "# Usually done to categorical variables\n",
    "def addDummies(data):\n",
    "    dummy_data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed_characteristics(seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating out the Gene expression Column and Cell Viability Column\n",
    "\n",
    "gene_expression = [g for g in training_features.columns if g.startswith('g-')]\n",
    "cell_viability = [c for c in training_features.columns if c.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our dimensions are really high, we can resort to \n",
    "# using PCA for dimensionality reduction, but is still able \n",
    "# to capture the characteristics of the data.\n",
    "\n",
    "# Now, this can be done by choosing a random dimension, and \n",
    "# having the same random state as before. By doing this\n",
    "# we observe that we do not encounter\n",
    "# any 'nan' errors during training.\n",
    "\n",
    "# Doing PCA for the Gene expression data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_genes = 20\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[gene_expression]), pd.DataFrame(testing_features[gene_expression])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_genes number of columns\n",
    "pca_genes = PCA(n_components = random_pca_dimension_genes, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_genes.fit_transform(data[gene_expression])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_genes = data_pca[:training_features.shape[0]] \n",
    "test_pca_genes = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_genes = pd.DataFrame(train_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "test_pca_genes = pd.DataFrame(test_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_genes), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_genes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing PCA for the Cell Viability Data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_cells = 32\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[cell_viability]), pd.DataFrame(testing_features[cell_viability])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_cells number of columns\n",
    "pca_cells = PCA(n_components = random_pca_dimension_cells, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_cells.fit_transform(data[cell_viability])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_cells = data_pca[:training_features.shape[0]]\n",
    "test_pca_cells = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_cells = pd.DataFrame(train_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "test_pca_cells = pd.DataFrame(test_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_cells), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_cells), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a desired threshold to calculate the VarianceThreshold.\n",
    "# As per the math all the Features with a training-set variance \n",
    "# lower than this threshold will be removed.\n",
    "variancethreshold = VarianceThreshold(threshold=0.7)\n",
    "\n",
    "# Combining training and test features to create a single dataset\n",
    "combined_data = training_features.append(testing_features)\n",
    "\n",
    "# Fits to the data, before transforming it\n",
    "combined_data_transformed = variancethreshold.fit_transform(combined_data.iloc[:, 4:])\n",
    "\n",
    "# Extracting the training and the testing data out of the\n",
    "# transformed data\n",
    "training_features_transformed = combined_data_transformed[ : training_features.shape[0]]\n",
    "testing_features_transformed = combined_data_transformed[-testing_features.shape[0] : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "training_features = pd.DataFrame(training_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "training_features = pd.concat([training_features, pd.DataFrame(training_features_transformed)], axis=1)\n",
    "\n",
    "# Extracting the testing features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "\n",
    "testing_features = pd.DataFrame(testing_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "testing_features = pd.concat([testing_features, pd.DataFrame(testing_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the columns\n",
    "\n",
    "train = training_features.merge(training_targets_scored, on='sig_id')\n",
    "\n",
    "# Removing rows with cp_type as ctl_vehicle \n",
    "# since control perturbations have no MoAs\n",
    "# We are also manually setting the drop type as \n",
    "# true because we do not want to include them back \n",
    "# as a new column.\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# Naturally, we have to get rid of them from the test dataset \n",
    "# as well\n",
    "\n",
    "test = testing_features[testing_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the columns of the drugs that are sold from\n",
    "# the train pandas dataframe\n",
    "\n",
    "target = train[training_targets_scored.columns]\n",
    "\n",
    "# Now that the ctl_vehicle drugs have been removed, we do not need\n",
    "# cp_type. So we can go ahead and remove that columns as well.\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "# extracting the columns in the targets \n",
    "\n",
    "target_columns = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilabel stratified K Fold import causes a small warning and we do not want\n",
    "# to show that in the notebook.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "folds = train.copy()\n",
    "number_of_folds = 3\n",
    "\n",
    "# creating a 3 fold multilabel stratified K Fold\n",
    "multilabel_k_fold = MultilabelStratifiedKFold(n_splits = number_of_folds)\n",
    "\n",
    "# Standard k fold splitting. Here we are splitting into number_of_folds folds\n",
    "\n",
    "for fol, (train_folds, validation_folds) in enumerate(multilabel_k_fold.split(X=train, y=target)):\n",
    "    folds.loc[validation_folds, 'kfold'] = int(fol)\n",
    "    \n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# Isolating out the feature columns. This is done by first \n",
    "# Isolating the columns that are not present in the target\n",
    "# followed by extracting the columns except the sig_id and \n",
    "# kfold.\n",
    "\n",
    "feature_columns = [c for c in addDummies(folds).columns if c not in target_columns]\n",
    "feature_columns = [c for c in feature_columns if c not in ['kfold','sig_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "max_epochs = 15\n",
    "# When training neural networks, it is common to use \n",
    "# weight decay where after each update, the weights \n",
    "# are multiplied by a factor slightly less than 1\n",
    "WEIGHT_DECAY = 1e-5\n",
    "# deciding the initial learning rate\n",
    "# It controls how quickly or slowly a neural\n",
    "# network model can learn a model or a problem.\n",
    "lr = 1e-3\n",
    "EARLY_STOPPING_STEPS = 11\n",
    "# Boolean to decide on stopping early when the \n",
    "# validation_loss > best_loss\n",
    "EARLY_STOP = True\n",
    "# number of features corresponding to the columns in the\n",
    "# targets\n",
    "num_features=len(feature_columns)\n",
    "# number of targets corresponding to the columns in the\n",
    "# features\n",
    "num_targets=len(target_columns)\n",
    "# in between neural netwrok size\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the training functions and performing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot validation loss\n",
    "valid_loss_list = []\n",
    "# to plot the training loss\n",
    "train_loss_list = []\n",
    "# to plot the best recorded loss\n",
    "best_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    # declaring the list as global to plot validation loss\n",
    "    global valid_loss_list\n",
    "    # declaring the training loss list as global to plot\n",
    "    # the training loss\n",
    "    global train_loss_list\n",
    "    # declaring the best loss list as global to plot the\n",
    "    # best losses recorded\n",
    "    global best_loss_list\n",
    "    \n",
    "    # setting the seed to start from the same number as \n",
    "    # explained previously\n",
    "    set_seed_characteristics(seed)\n",
    "    \n",
    "    # adding dummy variables to the training set\n",
    "    train = addDummies(folds)\n",
    "    # adding dummy variables to the test set\n",
    "    test_ = addDummies(test)\n",
    "    \n",
    "    # extracting the training rows numbers for the\n",
    "    # respective k fold values\n",
    "#     trn_idx = train[train['kfold'] != fold].index\n",
    "\n",
    "    # extracting the validating rows numbers for the\n",
    "    # respective k fold values\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    # Dropping all the rows from the training set\n",
    "    # that does not belong to this kth fold\n",
    "    train_necessary_rows = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    # Dropping all the rows from the valiadtion set\n",
    "    # that does not belong to this kth fold\n",
    "    valid_necessary_rows = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # splitting the x and y values for training set\n",
    "    train_features, train_targets  = train_necessary_rows[feature_columns].values, train_necessary_rows[target_columns].values\n",
    "    # splitting the x and y values for test set\n",
    "    validation_features, validation_targets =  valid_necessary_rows[feature_columns].values, valid_necessary_rows[target_columns].values\n",
    "    \n",
    "    # Converting the training data to standard pytorch \n",
    "    # dataset class format\n",
    "    train_dataset = MoADataset(train_features, train_targets)\n",
    "    \n",
    "    # Converting the validation data to standard pytorch \n",
    "    # dataset class format\n",
    "    valid_dataset = MoADataset(validation_features, validation_targets)\n",
    "    \n",
    "    # calling the pytorch data loading utility for the\n",
    "    # training set\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # calling the pytorch data loading utility for the\n",
    "    # validation set  \n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Declaring the model and can be tuned here\n",
    "    # using the hyper parameters\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # moving the model to GPU if available,\n",
    "    # else will run it on CPU itself\n",
    "    model.to(device_code)\n",
    "    \n",
    "    # A standard optimizer. Adam optimizer is widely used\n",
    "    # because it combines the advantages of the Adaptive gradient\n",
    "    # algorithm and the root mean square propogation. Basically, it does\n",
    "    # not stick to one learning rate and adapts it to the problem. \n",
    "    # It is widely known to offer good results really fast.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # We use a learning rate scheduler to converge to the lowest\n",
    "    # loss faster. This is also seen to provide higher accuracy.\n",
    "    # This can be tuned.\n",
    "    # Some of the optimizers I tried here are\n",
    "    # optim.lr_scheduler.OneCycleLR\n",
    "    # optim.lr_scheduler.StepLR\n",
    "    \n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.05, div_factor=1.5e3, \n",
    "                                              max_lr=1e-2, epochs=max_epochs, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    # after research I saw that the Binary cross\n",
    "    # entroy loss with sigmoid later works well\n",
    "    lossFunction = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # stops when the error starts increaseing\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    steps_before_early_stop = 0\n",
    "    # general out of fold array shape\n",
    "    out_of_fold = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    # declaring a very high value as an \n",
    "    # initial loss for each kth fold\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    # looping through the epochs\n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        # training the model\n",
    "        training_loss = trainingFunction(model, optimizer,scheduler, lossFunction, trainloader, device_code)\n",
    "        print(f\"FOLD: {fold}> EPOCH: {epoch}>>> training_loss: {training_loss}\")\n",
    "        train_loss_list.append(training_loss)\n",
    "        validation_loss, validation_predictions = validationFunction(model, lossFunction, validloader, device_code)\n",
    "        print(f\"FOLD: {fold}> EPOCH: {epoch}>>> validation_loss: {validation_loss}\")\n",
    "        valid_loss_list.append(validation_loss)\n",
    "        \n",
    "        # checking if the loss is decreasing\n",
    "        if validation_loss < best_loss:\n",
    "            best_loss = validation_loss\n",
    "            best_loss_list.append(best_loss)\n",
    "            # Updating the out of fold predictions\n",
    "            out_of_fold[val_idx] = validation_predictions\n",
    "            # saving the model and data for this kth fold\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        # Handling the increasing loss by calling \n",
    "        # early stopping\n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            # breaks out of the loop when this happens\n",
    "            steps_before_early_stop += 1\n",
    "            if (steps_before_early_stop >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    # extracting the x_test\n",
    "    x_test = test_[feature_columns].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(num_features=num_features,num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # uploading the saved data for this kth fold\n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    # again uploading the model to GPU, if available\n",
    "    model.to(device_code)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    # evaluates the model\n",
    "    predictions = inferenceFunction(model, testloader, device_code)\n",
    "    \n",
    "    return out_of_fold, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKFold(number_of_folds, seed):\n",
    "    # standard size for the out of fold predictions\n",
    "    out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "    # same size for all of the predictions\n",
    "    predictions = np.zeros((len(test), len(target_columns)))\n",
    "    \n",
    "    for each_k_fold in range(number_of_folds):\n",
    "        out_of_fold_, pred_ = run_training(each_k_fold, seed)\n",
    "        \n",
    "        # adding all the predictions\n",
    "        predictions += pred_ / number_of_folds\n",
    "        # adding all the out of fold predictions\n",
    "        out_of_fold += out_of_fold_\n",
    "        \n",
    "    return out_of_fold, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0> EPOCH: 0>>> training_loss: 0.19709343711233737\n",
      "FOLD: 0> EPOCH: 0>>> validation_loss: 0.01960303533290114\n",
      "FOLD: 0> EPOCH: 1>>> training_loss: 0.018754845774434144\n",
      "FOLD: 0> EPOCH: 1>>> validation_loss: 0.01819717873420034\n",
      "FOLD: 0> EPOCH: 2>>> training_loss: 0.018077932463952832\n",
      "FOLD: 0> EPOCH: 2>>> validation_loss: 0.017802675973091805\n",
      "FOLD: 0> EPOCH: 3>>> training_loss: 0.01803536176331896\n",
      "FOLD: 0> EPOCH: 3>>> validation_loss: 0.01800444456083434\n",
      "FOLD: 0> EPOCH: 4>>> training_loss: 0.018094486996989612\n",
      "FOLD: 0> EPOCH: 4>>> validation_loss: 0.018229046197874205\n",
      "FOLD: 0> EPOCH: 5>>> training_loss: 0.018123019037581376\n",
      "FOLD: 0> EPOCH: 5>>> validation_loss: 0.01794819741376809\n",
      "FOLD: 0> EPOCH: 6>>> training_loss: 0.01800273658713766\n",
      "FOLD: 0> EPOCH: 6>>> validation_loss: 0.017804615598704134\n",
      "FOLD: 0> EPOCH: 7>>> training_loss: 0.017884072042929317\n",
      "FOLD: 0> EPOCH: 7>>> validation_loss: 0.017912499154252665\n",
      "FOLD: 0> EPOCH: 8>>> training_loss: 0.01778823437476621\n",
      "FOLD: 0> EPOCH: 8>>> validation_loss: 0.01764864812472037\n",
      "FOLD: 0> EPOCH: 9>>> training_loss: 0.01754699534100622\n",
      "FOLD: 0> EPOCH: 9>>> validation_loss: 0.017344448688839165\n",
      "FOLD: 0> EPOCH: 10>>> training_loss: nan\n",
      "FOLD: 0> EPOCH: 10>>> validation_loss: nan\n",
      "FOLD: 0> EPOCH: 11>>> training_loss: nan\n",
      "FOLD: 0> EPOCH: 11>>> validation_loss: nan\n",
      "FOLD: 0> EPOCH: 12>>> training_loss: nan\n",
      "FOLD: 0> EPOCH: 12>>> validation_loss: nan\n",
      "FOLD: 0> EPOCH: 13>>> training_loss: nan\n",
      "FOLD: 0> EPOCH: 13>>> validation_loss: nan\n",
      "FOLD: 0> EPOCH: 14>>> training_loss: nan\n",
      "FOLD: 0> EPOCH: 14>>> validation_loss: nan\n",
      "FOLD: 1> EPOCH: 0>>> training_loss: 0.19684974846210102\n",
      "FOLD: 1> EPOCH: 0>>> validation_loss: 0.018888463399239948\n",
      "FOLD: 1> EPOCH: 1>>> training_loss: 0.018787048371285683\n",
      "FOLD: 1> EPOCH: 1>>> validation_loss: 0.017606635764241218\n",
      "FOLD: 1> EPOCH: 2>>> training_loss: 0.018037977625395874\n",
      "FOLD: 1> EPOCH: 2>>> validation_loss: 0.01777528990060091\n",
      "FOLD: 1> EPOCH: 3>>> training_loss: 0.018029173302635985\n",
      "FOLD: 1> EPOCH: 3>>> validation_loss: 0.017677879546369825\n",
      "FOLD: 1> EPOCH: 4>>> training_loss: 0.018120343986790157\n",
      "FOLD: 1> EPOCH: 4>>> validation_loss: 0.01796352570610387\n",
      "FOLD: 1> EPOCH: 5>>> training_loss: 0.018153624069608725\n",
      "FOLD: 1> EPOCH: 5>>> validation_loss: 0.017511954717338084\n",
      "FOLD: 1> EPOCH: 6>>> training_loss: 0.018104898315345005\n",
      "FOLD: 1> EPOCH: 6>>> validation_loss: 0.01786143822329385\n",
      "FOLD: 1> EPOCH: 7>>> training_loss: 0.01801108177691023\n",
      "FOLD: 1> EPOCH: 7>>> validation_loss: 0.01738070087241275\n",
      "FOLD: 1> EPOCH: 8>>> training_loss: 0.01779509351730443\n",
      "FOLD: 1> EPOCH: 8>>> validation_loss: 0.017243469426674502\n",
      "FOLD: 1> EPOCH: 9>>> training_loss: 0.017596515293404894\n",
      "FOLD: 1> EPOCH: 9>>> validation_loss: 0.017111141686992987\n",
      "FOLD: 1> EPOCH: 10>>> training_loss: 0.017286092151426576\n",
      "FOLD: 1> EPOCH: 10>>> validation_loss: 0.016793444247118063\n",
      "FOLD: 1> EPOCH: 11>>> training_loss: 0.016929517985354737\n",
      "FOLD: 1> EPOCH: 11>>> validation_loss: nan\n",
      "FOLD: 1> EPOCH: 12>>> training_loss: nan\n",
      "FOLD: 1> EPOCH: 12>>> validation_loss: nan\n",
      "FOLD: 1> EPOCH: 13>>> training_loss: nan\n",
      "FOLD: 1> EPOCH: 13>>> validation_loss: nan\n",
      "FOLD: 1> EPOCH: 14>>> training_loss: nan\n",
      "FOLD: 1> EPOCH: 14>>> validation_loss: nan\n",
      "FOLD: 2> EPOCH: 0>>> training_loss: 0.19600086680893758\n",
      "FOLD: 2> EPOCH: 0>>> validation_loss: 0.018957169353961946\n",
      "FOLD: 2> EPOCH: 1>>> training_loss: 0.018731170385159722\n",
      "FOLD: 2> EPOCH: 1>>> validation_loss: 0.01767250823655299\n",
      "FOLD: 2> EPOCH: 2>>> training_loss: 0.017974981815105116\n",
      "FOLD: 2> EPOCH: 2>>> validation_loss: 0.017781097841049944\n",
      "FOLD: 2> EPOCH: 3>>> training_loss: 0.018043140919945386\n",
      "FOLD: 2> EPOCH: 3>>> validation_loss: 0.017800877003797462\n",
      "FOLD: 2> EPOCH: 4>>> training_loss: 0.018128946791237225\n",
      "FOLD: 2> EPOCH: 4>>> validation_loss: 0.017685797810554505\n",
      "FOLD: 2> EPOCH: 5>>> training_loss: 0.018125871371200555\n",
      "FOLD: 2> EPOCH: 5>>> validation_loss: 0.017763032897242476\n",
      "FOLD: 2> EPOCH: 6>>> training_loss: 0.017964297625263338\n",
      "FOLD: 2> EPOCH: 6>>> validation_loss: 0.017649664995925768\n",
      "FOLD: 2> EPOCH: 7>>> training_loss: 0.017945124828000477\n",
      "FOLD: 2> EPOCH: 7>>> validation_loss: 0.017469575415764535\n",
      "FOLD: 2> EPOCH: 8>>> training_loss: 0.017743348128924863\n",
      "FOLD: 2> EPOCH: 8>>> validation_loss: 0.017390386361096587\n",
      "FOLD: 2> EPOCH: 9>>> training_loss: 0.01752359342902995\n",
      "FOLD: 2> EPOCH: 9>>> validation_loss: 0.017322471285504955\n",
      "FOLD: 2> EPOCH: 10>>> training_loss: 0.017322618240026403\n",
      "FOLD: 2> EPOCH: 10>>> validation_loss: 0.016967160254716875\n",
      "FOLD: 2> EPOCH: 11>>> training_loss: 0.016921001872270816\n",
      "FOLD: 2> EPOCH: 11>>> validation_loss: 0.016592560415821415\n",
      "FOLD: 2> EPOCH: 12>>> training_loss: 0.016528085525174742\n",
      "FOLD: 2> EPOCH: 12>>> validation_loss: 0.016462710579591137\n",
      "FOLD: 2> EPOCH: 13>>> training_loss: 0.01618854350992102\n",
      "FOLD: 2> EPOCH: 13>>> validation_loss: 0.01626749797058957\n",
      "FOLD: 2> EPOCH: 14>>> training_loss: 0.015957809894264322\n",
      "FOLD: 2> EPOCH: 14>>> validation_loss: 0.01624440864792892\n",
      "FOLD: 3> EPOCH: 0>>> training_loss: 0.19710092920460362\n",
      "FOLD: 3> EPOCH: 0>>> validation_loss: 0.020037622270839554\n",
      "FOLD: 3> EPOCH: 1>>> training_loss: 0.01898837826458864\n",
      "FOLD: 3> EPOCH: 1>>> validation_loss: 0.017754355339067322\n",
      "FOLD: 3> EPOCH: 2>>> training_loss: 0.018103793802939378\n",
      "FOLD: 3> EPOCH: 2>>> validation_loss: 0.017726673797837326\n",
      "FOLD: 3> EPOCH: 3>>> training_loss: 0.018077447193653645\n",
      "FOLD: 3> EPOCH: 3>>> validation_loss: 0.0176863840382014\n",
      "FOLD: 3> EPOCH: 4>>> training_loss: 0.018205719584038535\n",
      "FOLD: 3> EPOCH: 4>>> validation_loss: 0.017549075478953974\n",
      "FOLD: 3> EPOCH: 5>>> training_loss: 0.01814211160547332\n",
      "FOLD: 3> EPOCH: 5>>> validation_loss: 0.01782769313348191\n",
      "FOLD: 3> EPOCH: 6>>> training_loss: 0.018101944585110764\n",
      "FOLD: 3> EPOCH: 6>>> validation_loss: 0.017763766619775977\n",
      "FOLD: 3> EPOCH: 7>>> training_loss: 0.017967383081883094\n",
      "FOLD: 3> EPOCH: 7>>> validation_loss: 0.01738769156592233\n",
      "FOLD: 3> EPOCH: 8>>> training_loss: 0.017811162008460866\n",
      "FOLD: 3> EPOCH: 8>>> validation_loss: 0.017221047143851007\n",
      "FOLD: 3> EPOCH: 9>>> training_loss: 0.017594060601371198\n",
      "FOLD: 3> EPOCH: 9>>> validation_loss: 0.01710543217403548\n",
      "FOLD: 3> EPOCH: 10>>> training_loss: 0.017351017071350106\n",
      "FOLD: 3> EPOCH: 10>>> validation_loss: 0.01686692035623959\n",
      "FOLD: 3> EPOCH: 11>>> training_loss: 0.01695602832054629\n",
      "FOLD: 3> EPOCH: 11>>> validation_loss: 0.016498912099216667\n",
      "FOLD: 3> EPOCH: 12>>> training_loss: 0.01656040405510988\n",
      "FOLD: 3> EPOCH: 12>>> validation_loss: 0.01623098576175315\n",
      "FOLD: 3> EPOCH: 13>>> training_loss: 0.016198543943223637\n",
      "FOLD: 3> EPOCH: 13>>> validation_loss: 0.016102884284087588\n",
      "FOLD: 3> EPOCH: 14>>> training_loss: 0.015977818051708746\n",
      "FOLD: 3> EPOCH: 14>>> validation_loss: 0.016055015634213174\n",
      "FOLD: 4> EPOCH: 0>>> training_loss: 0.19714624664375505\n",
      "FOLD: 4> EPOCH: 0>>> validation_loss: 0.01878036811415638\n",
      "FOLD: 4> EPOCH: 1>>> training_loss: 0.018792602176322906\n",
      "FOLD: 4> EPOCH: 1>>> validation_loss: 0.01771576963365078\n",
      "FOLD: 4> EPOCH: 2>>> training_loss: 0.01812038540502582\n",
      "FOLD: 4> EPOCH: 2>>> validation_loss: 0.01766263297093766\n",
      "FOLD: 4> EPOCH: 3>>> training_loss: 0.018072296527717684\n",
      "FOLD: 4> EPOCH: 3>>> validation_loss: 0.017720749894423144\n",
      "FOLD: 4> EPOCH: 4>>> training_loss: 0.018176336019242657\n",
      "FOLD: 4> EPOCH: 4>>> validation_loss: 0.017693026310631205\n",
      "FOLD: 4> EPOCH: 5>>> training_loss: 0.018184851912305386\n",
      "FOLD: 4> EPOCH: 5>>> validation_loss: 0.017641537503472398\n",
      "FOLD: 4> EPOCH: 6>>> training_loss: 0.01809164306938552\n",
      "FOLD: 4> EPOCH: 6>>> validation_loss: 0.01763113620025771\n",
      "FOLD: 4> EPOCH: 7>>> training_loss: 0.01790956128991441\n",
      "FOLD: 4> EPOCH: 7>>> validation_loss: 0.017237193483327116\n",
      "FOLD: 4> EPOCH: 8>>> training_loss: 0.017778135715564865\n",
      "FOLD: 4> EPOCH: 8>>> validation_loss: 0.01721428968012333\n",
      "FOLD: 4> EPOCH: 9>>> training_loss: 0.017632606098711683\n",
      "FOLD: 4> EPOCH: 9>>> validation_loss: 0.016945021812404905\n",
      "FOLD: 4> EPOCH: 10>>> training_loss: 0.017308339009417105\n",
      "FOLD: 4> EPOCH: 10>>> validation_loss: 0.016781179500477656\n",
      "FOLD: 4> EPOCH: 11>>> training_loss: 0.016919259027152963\n",
      "FOLD: 4> EPOCH: 11>>> validation_loss: 0.01648077169167144\n",
      "FOLD: 4> EPOCH: 12>>> training_loss: nan\n",
      "FOLD: 4> EPOCH: 12>>> validation_loss: nan\n",
      "FOLD: 4> EPOCH: 13>>> training_loss: nan\n",
      "FOLD: 4> EPOCH: 13>>> validation_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 4> EPOCH: 14>>> training_loss: nan\n",
      "FOLD: 4> EPOCH: 14>>> validation_loss: nan\n",
      "FOLD: 5> EPOCH: 0>>> training_loss: 0.19630700211164248\n",
      "FOLD: 5> EPOCH: 0>>> validation_loss: 0.018422227831823484\n",
      "FOLD: 5> EPOCH: 1>>> training_loss: 0.018733786723446885\n",
      "FOLD: 5> EPOCH: 1>>> validation_loss: 0.017678661830723287\n",
      "FOLD: 5> EPOCH: 2>>> training_loss: 0.018046016165908292\n",
      "FOLD: 5> EPOCH: 2>>> validation_loss: 0.017863915860652925\n",
      "FOLD: 5> EPOCH: 3>>> training_loss: 0.01814552350421843\n",
      "FOLD: 5> EPOCH: 3>>> validation_loss: 0.01733304320701531\n",
      "FOLD: 5> EPOCH: 4>>> training_loss: 0.0181428201520713\n",
      "FOLD: 5> EPOCH: 4>>> validation_loss: 0.017605386461530412\n",
      "FOLD: 5> EPOCH: 5>>> training_loss: 0.018182347308615263\n",
      "FOLD: 5> EPOCH: 5>>> validation_loss: 0.017544750443526675\n",
      "FOLD: 5> EPOCH: 6>>> training_loss: 0.01813198482274141\n",
      "FOLD: 5> EPOCH: 6>>> validation_loss: 0.017346819224102156\n",
      "FOLD: 5> EPOCH: 7>>> training_loss: 0.01797411014841309\n",
      "FOLD: 5> EPOCH: 7>>> validation_loss: 0.01719432526401111\n",
      "FOLD: 5> EPOCH: 8>>> training_loss: 0.01783503074813815\n",
      "FOLD: 5> EPOCH: 8>>> validation_loss: 0.01707107720098325\n",
      "FOLD: 5> EPOCH: 9>>> training_loss: 0.01761842605244959\n",
      "FOLD: 5> EPOCH: 9>>> validation_loss: 0.01674578964178051\n",
      "FOLD: 5> EPOCH: 10>>> training_loss: 0.01731931241862114\n",
      "FOLD: 5> EPOCH: 10>>> validation_loss: 0.01662219398255859\n",
      "FOLD: 5> EPOCH: 11>>> training_loss: 0.01695524836953693\n",
      "FOLD: 5> EPOCH: 11>>> validation_loss: 0.016350934973784856\n",
      "FOLD: 5> EPOCH: 12>>> training_loss: 0.016573978027383102\n",
      "FOLD: 5> EPOCH: 12>>> validation_loss: 0.0161158577938165\n",
      "FOLD: 5> EPOCH: 13>>> training_loss: 0.01621808053497647\n",
      "FOLD: 5> EPOCH: 13>>> validation_loss: 0.015933863845254692\n",
      "FOLD: 5> EPOCH: 14>>> training_loss: 0.015975756037220793\n",
      "FOLD: 5> EPOCH: 14>>> validation_loss: 0.015932575267340456\n",
      "FOLD: 6> EPOCH: 0>>> training_loss: 0.1961559250161148\n",
      "FOLD: 6> EPOCH: 0>>> validation_loss: 0.01908740901521274\n",
      "FOLD: 6> EPOCH: 1>>> training_loss: 0.018812821719879858\n",
      "FOLD: 6> EPOCH: 1>>> validation_loss: 0.018032006520245756\n",
      "FOLD: 6> EPOCH: 2>>> training_loss: 0.018061628619444024\n",
      "FOLD: 6> EPOCH: 2>>> validation_loss: 0.01781299441520657\n",
      "FOLD: 6> EPOCH: 3>>> training_loss: 0.018079715850235576\n",
      "FOLD: 6> EPOCH: 3>>> validation_loss: 0.018076894991099834\n",
      "FOLD: 6> EPOCH: 4>>> training_loss: 0.018163046874949847\n",
      "FOLD: 6> EPOCH: 4>>> validation_loss: 0.017829847761562892\n",
      "FOLD: 6> EPOCH: 5>>> training_loss: 0.018133108139423877\n",
      "FOLD: 6> EPOCH: 5>>> validation_loss: 0.017942422974322525\n",
      "FOLD: 6> EPOCH: 6>>> training_loss: 0.01808611454267332\n",
      "FOLD: 6> EPOCH: 6>>> validation_loss: 0.017795674369803498\n",
      "FOLD: 6> EPOCH: 7>>> training_loss: 0.017957082334725025\n",
      "FOLD: 6> EPOCH: 7>>> validation_loss: 0.017745855743331568\n",
      "FOLD: 6> EPOCH: 8>>> training_loss: 0.017790580412499535\n",
      "FOLD: 6> EPOCH: 8>>> validation_loss: 0.017485594509967735\n",
      "FOLD: 6> EPOCH: 9>>> training_loss: 0.017580997424869283\n",
      "FOLD: 6> EPOCH: 9>>> validation_loss: 0.01724346059241465\n",
      "FOLD: 6> EPOCH: 10>>> training_loss: nan\n",
      "FOLD: 6> EPOCH: 10>>> validation_loss: nan\n",
      "FOLD: 6> EPOCH: 11>>> training_loss: nan\n",
      "FOLD: 6> EPOCH: 11>>> validation_loss: nan\n",
      "FOLD: 6> EPOCH: 12>>> training_loss: nan\n",
      "FOLD: 6> EPOCH: 12>>> validation_loss: nan\n",
      "FOLD: 6> EPOCH: 13>>> training_loss: nan\n",
      "FOLD: 6> EPOCH: 13>>> validation_loss: nan\n",
      "FOLD: 6> EPOCH: 14>>> training_loss: nan\n",
      "FOLD: 6> EPOCH: 14>>> validation_loss: nan\n",
      "FOLD: 7> EPOCH: 0>>> training_loss: 0.19633617286470909\n",
      "FOLD: 7> EPOCH: 0>>> validation_loss: 0.021510376408696175\n",
      "FOLD: 7> EPOCH: 1>>> training_loss: 0.018699123921975928\n",
      "FOLD: 7> EPOCH: 1>>> validation_loss: 0.018002340250781606\n",
      "FOLD: 7> EPOCH: 2>>> training_loss: 0.01806345154323335\n",
      "FOLD: 7> EPOCH: 2>>> validation_loss: 0.017922191534723554\n",
      "FOLD: 7> EPOCH: 3>>> training_loss: 0.018028197430291222\n",
      "FOLD: 7> EPOCH: 3>>> validation_loss: 0.018223846171583447\n",
      "FOLD: 7> EPOCH: 4>>> training_loss: 0.018103981619658593\n",
      "FOLD: 7> EPOCH: 4>>> validation_loss: 0.01814808685864721\n",
      "FOLD: 7> EPOCH: 5>>> training_loss: 0.01813976636644706\n",
      "FOLD: 7> EPOCH: 5>>> validation_loss: 0.017997223192027637\n",
      "FOLD: 7> EPOCH: 6>>> training_loss: 0.018009432600539863\n",
      "FOLD: 7> EPOCH: 6>>> validation_loss: 0.01795134459223066\n",
      "FOLD: 7> EPOCH: 7>>> training_loss: 0.017948189011886474\n",
      "FOLD: 7> EPOCH: 7>>> validation_loss: 0.017752677920673574\n",
      "FOLD: 7> EPOCH: 8>>> training_loss: 0.017818095433769873\n",
      "FOLD: 7> EPOCH: 8>>> validation_loss: 0.017561903329832214\n",
      "FOLD: 7> EPOCH: 9>>> training_loss: 0.01756221514110812\n",
      "FOLD: 7> EPOCH: 9>>> validation_loss: 0.01743661963513919\n",
      "FOLD: 7> EPOCH: 10>>> training_loss: 0.017237664112959863\n",
      "FOLD: 7> EPOCH: 10>>> validation_loss: 0.017143396234938078\n",
      "FOLD: 7> EPOCH: 11>>> training_loss: 0.01688227058662566\n",
      "FOLD: 7> EPOCH: 11>>> validation_loss: 0.016842234108064857\n",
      "FOLD: 7> EPOCH: 12>>> training_loss: 0.016525992656482268\n",
      "FOLD: 7> EPOCH: 12>>> validation_loss: 0.016686689906886647\n",
      "FOLD: 7> EPOCH: 13>>> training_loss: 0.01615039350217793\n",
      "FOLD: 7> EPOCH: 13>>> validation_loss: 0.016474882513284682\n",
      "FOLD: 7> EPOCH: 14>>> training_loss: 0.01591118805496245\n",
      "FOLD: 7> EPOCH: 14>>> validation_loss: 0.016452080729816642\n",
      "FOLD: 8> EPOCH: 0>>> training_loss: 0.19636013539972139\n",
      "FOLD: 8> EPOCH: 0>>> validation_loss: 0.01896379632609231\n",
      "FOLD: 8> EPOCH: 1>>> training_loss: 0.01869075037358166\n",
      "FOLD: 8> EPOCH: 1>>> validation_loss: 0.018068815661328178\n",
      "FOLD: 8> EPOCH: 2>>> training_loss: 0.018037758864052473\n",
      "FOLD: 8> EPOCH: 2>>> validation_loss: 0.017814860413117067\n",
      "FOLD: 8> EPOCH: 3>>> training_loss: 0.018039475384991146\n",
      "FOLD: 8> EPOCH: 3>>> validation_loss: 0.017804344530616488\n",
      "FOLD: 8> EPOCH: 4>>> training_loss: 0.01809961181797063\n",
      "FOLD: 8> EPOCH: 4>>> validation_loss: 0.01798589833612953\n",
      "FOLD: 8> EPOCH: 5>>> training_loss: 0.018067403521666057\n",
      "FOLD: 8> EPOCH: 5>>> validation_loss: 0.017999153078666754\n",
      "FOLD: 8> EPOCH: 6>>> training_loss: 0.01805379510251353\n",
      "FOLD: 8> EPOCH: 6>>> validation_loss: 0.01796553994395903\n",
      "FOLD: 8> EPOCH: 7>>> training_loss: 0.017941163985426372\n",
      "FOLD: 8> EPOCH: 7>>> validation_loss: 0.017783719141568455\n",
      "FOLD: 8> EPOCH: 8>>> training_loss: 0.017772552201638907\n",
      "FOLD: 8> EPOCH: 8>>> validation_loss: 0.017728543334773608\n",
      "FOLD: 8> EPOCH: 9>>> training_loss: 0.017634083667595217\n",
      "FOLD: 8> EPOCH: 9>>> validation_loss: 0.017571200616657734\n",
      "FOLD: 8> EPOCH: 10>>> training_loss: 0.017283618835955375\n",
      "FOLD: 8> EPOCH: 10>>> validation_loss: 0.01711044463195971\n",
      "FOLD: 8> EPOCH: 11>>> training_loss: 0.016974900092652314\n",
      "FOLD: 8> EPOCH: 11>>> validation_loss: 0.016825001846466747\n",
      "FOLD: 8> EPOCH: 12>>> training_loss: 0.01657881113643303\n",
      "FOLD: 8> EPOCH: 12>>> validation_loss: 0.01654379583363022\n",
      "FOLD: 8> EPOCH: 13>>> training_loss: nan\n",
      "FOLD: 8> EPOCH: 13>>> validation_loss: nan\n",
      "FOLD: 8> EPOCH: 14>>> training_loss: nan\n",
      "FOLD: 8> EPOCH: 14>>> validation_loss: nan\n",
      "FOLD: 9> EPOCH: 0>>> training_loss: 0.19646784929938396\n",
      "FOLD: 9> EPOCH: 0>>> validation_loss: 0.0193365107689585\n",
      "FOLD: 9> EPOCH: 1>>> training_loss: 0.018836043102962108\n",
      "FOLD: 9> EPOCH: 1>>> validation_loss: 0.018226033502391405\n",
      "FOLD: 9> EPOCH: 2>>> training_loss: 0.01801316290611588\n",
      "FOLD: 9> EPOCH: 2>>> validation_loss: 0.018093781865068843\n",
      "FOLD: 9> EPOCH: 3>>> training_loss: 0.018025462976792483\n",
      "FOLD: 9> EPOCH: 3>>> validation_loss: 0.018270182103982995\n",
      "FOLD: 9> EPOCH: 4>>> training_loss: 0.01812869563554097\n",
      "FOLD: 9> EPOCH: 4>>> validation_loss: 0.018288855547351497\n",
      "FOLD: 9> EPOCH: 5>>> training_loss: 0.018098924664665967\n",
      "FOLD: 9> EPOCH: 5>>> validation_loss: 0.017870802352471012\n",
      "FOLD: 9> EPOCH: 6>>> training_loss: 0.018050492744181534\n",
      "FOLD: 9> EPOCH: 6>>> validation_loss: 0.018061361807797636\n",
      "FOLD: 9> EPOCH: 7>>> training_loss: 0.017967749112752843\n",
      "FOLD: 9> EPOCH: 7>>> validation_loss: 0.01794291982161147\n",
      "FOLD: 9> EPOCH: 8>>> training_loss: 0.017809493883142194\n",
      "FOLD: 9> EPOCH: 8>>> validation_loss: 0.01782874885414328\n",
      "FOLD: 9> EPOCH: 9>>> training_loss: 0.01755666036255248\n",
      "FOLD: 9> EPOCH: 9>>> validation_loss: 0.017469383616532597\n",
      "FOLD: 9> EPOCH: 10>>> training_loss: 0.017259522356261714\n",
      "FOLD: 9> EPOCH: 10>>> validation_loss: 0.017247304187289307\n",
      "FOLD: 9> EPOCH: 11>>> training_loss: 0.016910504549741745\n",
      "FOLD: 9> EPOCH: 11>>> validation_loss: 0.017094166257551738\n",
      "FOLD: 9> EPOCH: 12>>> training_loss: 0.016529348802460438\n",
      "FOLD: 9> EPOCH: 12>>> validation_loss: 0.0167407131886908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 9> EPOCH: 13>>> training_loss: 0.016176862931511934\n",
      "FOLD: 9> EPOCH: 13>>> validation_loss: 0.016531218056167876\n",
      "FOLD: 9> EPOCH: 14>>> training_loss: 0.015969420918851222\n",
      "FOLD: 9> EPOCH: 14>>> validation_loss: 0.01652500722557306\n",
      " The Cross validation loss is :>>  0.015232326993812864\n"
     ]
    }
   ],
   "source": [
    "# setting a standard seed number\n",
    "SEED = [55]\n",
    "# general out of fold array shape\n",
    "out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "# general predictions array shape\n",
    "predictions = np.zeros((len(test), len(target_columns)))\n",
    "\n",
    "# for seed in SEED:\n",
    "out_of_fold_, predictions_ = executeKFold(number_of_folds, SEED)\n",
    "out_of_fold += out_of_fold_ / len(SEED)\n",
    "predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_columns] = out_of_fold\n",
    "test[target_columns] = predictions\n",
    "\n",
    "valid_results = training_targets_scored.drop(columns=target_columns).merge(train[['sig_id']+target_columns], on='sig_id', how='left').fillna(0)\n",
    "# Given true values\n",
    "y_true = training_targets_scored[target_columns].values\n",
    "# Predicted values\n",
    "y_pred = valid_results[target_columns].values\n",
    "score = 0\n",
    "\n",
    "for i in range(len(target_columns)):\n",
    "    score_target = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_target / target.shape[1]  \n",
    "    \n",
    "print(\" The Cross validation loss is :>> \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Validation loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b8c148b80>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b8c09cac0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Best recorded loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3b8c082100>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
