{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action (MoA) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some of the important terms used in the headings of the tables are presented here:\n",
    "    \n",
    "    g - : signifies gene expression data\n",
    "    c - : signifies cell expression data\n",
    "    cp_type : indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\n",
    "    NOTE: (samples with control perturbations don't have MoAs)\n",
    "    cp_time - treatment duration (24,48,72) Hours\n",
    "    cp_dose - Dosage - HIGH or LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the multi label stratified k-fold \n",
    "# cross validator\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Initial random imports\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Importing pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device_code = 'cuda'\n",
    "else:\n",
    "    device_code = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the seed, so that every time the seed is started from the same number\n",
    "\n",
    "def set_seed_characteristics(seed=55):\n",
    "    # Setting a random seed value\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    # for guaranteering the reproducability of numbers by setting seed for NumPy\n",
    "    \n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    # for setting the seed for cuda or cpu\n",
    "    \n",
    "    torch.manual_seed(seed) \n",
    "\n",
    "    # To ensure that Pytorch doesnt just switch to the fastest possible algorithm but \n",
    "    # ensures that it selects a deterministic algorithm\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.read_csv('input/train_features.csv')\n",
    "# Reading the head rows and columns of train features\n",
    "training_features_head = training_features.head()\n",
    "\n",
    "training_targets_scored = pd.read_csv('input/train_targets_scored.csv')\n",
    "# Reading the head rows and columns of train targets scored\n",
    "training_targets_scored_head = training_targets_scored.head()\n",
    "\n",
    "testing_features = pd.read_csv('input/test_features.csv')\n",
    "# Reading the head rows and columns of train targets non-scored\n",
    "testing_features_head = testing_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - training features \n",
    "training_features_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - train targets scored \n",
    "training_targets_scored_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303 -0.1193   \n",
       "1 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690 -0.5382   \n",
       "2 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530 -1.0140   \n",
       "3 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325 -0.9005   \n",
       "4 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742  1.0900   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2  0.8662  1.0160  0.4924 -0.1942  \n",
       "3  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4 -0.2962 -0.5313  0.9931  1.8380  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - test features\n",
    "testing_features_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset classes, training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch data loader implementation of MoA dataset\n",
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return train_tensor_dictionary\n",
    "\n",
    "# Pytorch data loader implementation of test dataset\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        test_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return test_tensor_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pytorch model for the MoA determination\n",
    "\n",
    "# class Model(nn.Module):\n",
    "    \n",
    "#     # Instantiaing all the models before utilizing\n",
    "#     # them later in the forward function.\n",
    "#     def __init__(self, num_features, num_targets, hidden_size):\n",
    "        \n",
    "#         # super keyword used to access data from the parent\n",
    "#         # pytorch.nn.Module class\n",
    "#         super(Model, self).__init__()\n",
    "#         # Applying batch normalization. This is done to standardize\n",
    "#         # the input for each mini batches and will help reduce the\n",
    "#         # number of epochs for which the training is done. This limits\n",
    "#         # the covariate shift (this is the value by which the hidden\n",
    "#         # layer values shift around) and allows to learn from a more \n",
    "#         # stable set of data. Sometimes, it also allows for a\n",
    "#         # higher learning rate.This is also used for regularization\n",
    "#         # and helps reduce over fitting. Generally, if batch \n",
    "#         # normalization is used, you can use a smaller dropout,\n",
    "#         # which in turn means that lesser layers can be lost \n",
    "#         # in every step.\n",
    "#         self.batch_norm1 = nn.BatchNorm1d(num_features)        \n",
    "#         # For regularization purposes the dropout is set\n",
    "#         # This is done by setting a probablity. Random \n",
    "#         # neural networks are picked at a probablity, say p\n",
    "#         # or dropped at a probablity of 1-p. This is essential \n",
    "#         # to prevent overfitiing of the model and also reduces\n",
    "#         # the computation time. A fully connected neural network, if\n",
    "#         # run without dropout will start forming dependancies between\n",
    "#         # each other and this can lead to over-fitting.\n",
    "#         self.dropout1 = nn.Dropout(0.2)\n",
    "#         # nn.utils.weight_norm : This is weight normalization. Usually,\n",
    "#         #                        faster than batch normalization\n",
    "#         # nn.Linear : Applying linear transform to the incoming data\n",
    "#         #             and creates a single layer feed forward network.\n",
    "#         # input size : num_features\n",
    "#         # output size : hidden_size\n",
    "#         self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "#         self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "#         self.dropout2 = nn.Dropout(0.2)\n",
    "#         # input size : hidden_size\n",
    "#         # output size : hidden_size\n",
    "#         self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "#         self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "#         self.dropout3 = nn.Dropout(0.25)\n",
    "#         # input size : hidden_size\n",
    "#         # output size : num_targets\n",
    "#         self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "#     # The forward function basically defines the model\n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = self.batch_norm1(x)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = F.relu(self.dense1(x))\n",
    "        \n",
    "#         x = self.batch_norm2(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = F.relu(self.dense2(x))\n",
    "        \n",
    "#         x = self.batch_norm3(x)\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.dense3(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch model for the MoA determination\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    # Instantiaing all the models before utilizing\n",
    "    # them later in the forward function.\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        \n",
    "        # super keyword used to access data from the parent\n",
    "        # pytorch.nn.Module class\n",
    "        super(Model, self).__init__()\n",
    "        # Applying batch normalization. This is done to standardize\n",
    "        # the input for each mini batches and will help reduce the\n",
    "        # number of epochs for which the training is done. This limits\n",
    "        # the covariate shift (this is the value by which the hidden\n",
    "        # layer values shift around) and allows to learn from a more \n",
    "        # stable set of data. Sometimes, it also allows for a\n",
    "        # higher learning rate.This is also used for regularization\n",
    "        # and helps reduce over fitting. Generally, if batch \n",
    "        # normalization is used, you can use a smaller dropout,\n",
    "        # which in turn means that lesser layers can be lost \n",
    "        # in every step.\n",
    "        self.batch_normalization_1 = nn.BatchNorm1d(num_features)        \n",
    "        # For regularization purposes the dropout is set\n",
    "        # This is done by setting a probablity. Random \n",
    "        # neural networks are picked at a probablity, say p\n",
    "        # or dropped at a probablity of 1-p. This is essential \n",
    "        # to prevent overfitiing of the model and also reduces\n",
    "        # the computation time. A fully connected neural network, if\n",
    "        # run without dropout will start forming dependancies between\n",
    "        # each other and this can lead to over-fitting.\n",
    "        self.dropoutlayer_1 = nn.Dropout(0.2)\n",
    "        # nn.utils.weight_norm : This is weight normalization. Usually,\n",
    "        #                        faster than batch normalization\n",
    "        # nn.Linear : Applying linear transform to the incoming data\n",
    "        #             and creates a single layer feed forward network.\n",
    "        # input size : num_features\n",
    "        # output size : hidden_size\n",
    "        self.denselayer_1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_normalization_2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropoutlayer_2 = nn.Dropout(0.2)\n",
    "        # input size : hidden_size\n",
    "        # output size : hidden_size\n",
    "        self.denselayer_2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_normalization_3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropoutlayer_3 = nn.Dropout(0.1)\n",
    "        # input size : hidden_size\n",
    "        # output size : hidden_size\n",
    "        self.denselayer_3 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_normalization_4 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropoutlayer_4 = nn.Dropout(0.1)\n",
    "        # input size : hidden_size\n",
    "        # output size : hidden_size\n",
    "        self.denselayer_4 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        \n",
    "        self.batch_normalization_5 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropoutlayer_5 = nn.Dropout(0.1)\n",
    "        # input size : hidden_size\n",
    "        # output size : num_targets\n",
    "        self.denselayer_5 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    # The forward function basically defines the model\n",
    "    def forward(self, forward_x):\n",
    "        \n",
    "        forward_x = self.batch_normalization_1(forward_x)\n",
    "        forward_x = self.dropoutlayer_1(forward_x)\n",
    "        forward_x = F.relu(self.denselayer_1(forward_x))\n",
    "        \n",
    "        forward_x = self.batch_normalization_2(forward_x)\n",
    "        forward_x = self.dropoutlayer_2(forward_x)\n",
    "        forward_x = F.relu(self.denselayer_2(forward_x))\n",
    "        \n",
    "        forward_x = self.batch_normalization_3(forward_x)\n",
    "        forward_x = self.dropoutlayer_3(forward_x)\n",
    "        forward_x = self.denselayer_3(forward_x)\n",
    "        \n",
    "        forward_x = self.batch_normalization_4(forward_x)\n",
    "        forward_x = self.dropoutlayer_4(forward_x)\n",
    "        forward_x = self.denselayer_4(forward_x)\n",
    "\n",
    "        forward_x = self.batch_normalization_5(forward_x)\n",
    "        forward_x = self.dropoutlayer_5(forward_x)\n",
    "        forward_x = self.denselayer_5(forward_x)\n",
    "        \n",
    "        return forward_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def trainingFunction(model, optimizer, scheduler, lossFunction, trainloader, device_code):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for training_data in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = training_data['x'].to(device_code), training_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        training_loss += loss.item()    \n",
    "    training_loss /= len(trainloader) \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate the model\n",
    "def validationFunction(model, lossFunction, validationloader, device_code):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_predictions = []   \n",
    "    for validation_data in validationloader:\n",
    "        inputs, targets = validation_data['x'].to(device_code), validation_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        validation_loss += loss.item()\n",
    "        validation_predictions.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    validation_loss /= len(validationloader)\n",
    "    validation_predictions = np.concatenate(validation_predictions)\n",
    "    return validation_loss, validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the inference function\n",
    "def inferenceFunction(model, inferenceloader, device_code):\n",
    "    model.eval()\n",
    "    inferences = [] \n",
    "    for data in inferenceloader:\n",
    "        inputs = data['x'].to(device_code)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        inferences.append(outputs.sigmoid().detach().cpu().numpy())   \n",
    "    inferences = np.concatenate(inferences)  \n",
    "    return inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dummy inserts to the cp_time and cp_dose columns\n",
    "# Usually done to categorical variables\n",
    "def addDummies(data):\n",
    "    dummy_data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed_characteristics(seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating out the Gene expression Column and Cell Viability Column\n",
    "\n",
    "gene_expression = [g for g in training_features.columns if g.startswith('g-')]\n",
    "cell_viability = [c for c in training_features.columns if c.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our dimensions are really high, we can resort to \n",
    "# using PCA for dimensionality reduction, but is still able \n",
    "# to capture the characteristics of the data.\n",
    "\n",
    "# Now, this can be done by choosing a random dimension, and \n",
    "# having the same random state as before. By doing this\n",
    "# we observe that we do not encounter\n",
    "# any 'nan' errors during training.\n",
    "\n",
    "# Doing PCA for the Gene expression data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_genes = 20\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[gene_expression]), pd.DataFrame(testing_features[gene_expression])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_genes number of columns\n",
    "pca_genes = PCA(n_components = random_pca_dimension_genes, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_genes.fit_transform(data[gene_expression])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_genes = data_pca[:training_features.shape[0]] \n",
    "test_pca_genes = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_genes = pd.DataFrame(train_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "test_pca_genes = pd.DataFrame(test_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_genes), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_genes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing PCA for the Cell Viability Data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_cells = 32\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[cell_viability]), pd.DataFrame(testing_features[cell_viability])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_cells number of columns\n",
    "pca_cells = PCA(n_components = random_pca_dimension_cells, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_cells.fit_transform(data[cell_viability])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_cells = data_pca[:training_features.shape[0]]\n",
    "test_pca_cells = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_cells = pd.DataFrame(train_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "test_pca_cells = pd.DataFrame(test_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_cells), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_cells), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a desired threshold to calculate the VarianceThreshold.\n",
    "# As per the math all the Features with a training-set variance \n",
    "# lower than this threshold will be removed.\n",
    "variancethreshold = VarianceThreshold(threshold=0.7)\n",
    "\n",
    "# Combining training and test features to create a single dataset\n",
    "combined_data = training_features.append(testing_features)\n",
    "\n",
    "# Fits to the data, before transforming it\n",
    "combined_data_transformed = variancethreshold.fit_transform(combined_data.iloc[:, 4:])\n",
    "\n",
    "# Extracting the training and the testing data out of the\n",
    "# transformed data\n",
    "training_features_transformed = combined_data_transformed[ : training_features.shape[0]]\n",
    "testing_features_transformed = combined_data_transformed[-testing_features.shape[0] : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "training_features = pd.DataFrame(training_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "training_features = pd.concat([training_features, pd.DataFrame(training_features_transformed)], axis=1)\n",
    "\n",
    "# Extracting the testing features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "\n",
    "testing_features = pd.DataFrame(testing_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "testing_features = pd.concat([testing_features, pd.DataFrame(testing_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the columns\n",
    "\n",
    "train = training_features.merge(training_targets_scored, on='sig_id')\n",
    "\n",
    "# Removing rows with cp_type as ctl_vehicle \n",
    "# since control perturbations have no MoAs\n",
    "# We are also manually setting the drop type as \n",
    "# true because we do not want to include them back \n",
    "# as a new column.\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# Naturally, we have to get rid of them from the test dataset \n",
    "# as well\n",
    "\n",
    "test = testing_features[testing_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the columns of the drugs that are sold from\n",
    "# the train pandas dataframe\n",
    "\n",
    "target = train[training_targets_scored.columns]\n",
    "\n",
    "# Now that the ctl_vehicle drugs have been removed, we do not need\n",
    "# cp_type. So we can go ahead and remove that columns as well.\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "# extracting the columns in the targets \n",
    "\n",
    "target_columns = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilabel stratified K Fold import causes a small warning and we do not want\n",
    "# to show that in the notebook.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "folds = train.copy()\n",
    "number_of_folds = 3\n",
    "\n",
    "# creating a 3 fold multilabel stratified K Fold\n",
    "multilabel_k_fold = MultilabelStratifiedKFold(n_splits = number_of_folds)\n",
    "\n",
    "# Standard k fold splitting. Here we are splitting into number_of_folds folds\n",
    "\n",
    "for fol, (train_folds, validation_folds) in enumerate(multilabel_k_fold.split(X=train, y=target)):\n",
    "    folds.loc[validation_folds, 'kfold'] = int(fol)\n",
    "    \n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# Isolating out the feature columns. This is done by first \n",
    "# Isolating the columns that are not present in the target\n",
    "# followed by extracting the columns except the sig_id and \n",
    "# kfold.\n",
    "\n",
    "feature_columns = [c for c in addDummies(folds).columns if c not in target_columns]\n",
    "feature_columns = [c for c in feature_columns if c not in ['kfold','sig_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "max_epochs = 16\n",
    "# When training neural networks, it is common to use \n",
    "# weight decay where after each update, the weights \n",
    "# are multiplied by a factor slightly less than 1\n",
    "weight_decay = 1e-5\n",
    "# deciding the initial learning rate\n",
    "# It controls how quickly or slowly a neural\n",
    "# network model can learn a model or a problem.\n",
    "lr = 1e-3\n",
    "# Boolean to decide on stopping early when the \n",
    "# validation_loss > best_loss\n",
    "bool_early_stop = True\n",
    "# steps to execute before early stopping\n",
    "steps_early_stopping= 10\n",
    "# number of features corresponding to the columns in the\n",
    "# targets\n",
    "num_features=len(feature_columns)\n",
    "# number of targets corresponding to the columns in the\n",
    "# features\n",
    "num_targets=len(target_columns)\n",
    "# in between neural netwrok size\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the training functions and performing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot validation loss\n",
    "valid_loss_list = []\n",
    "# to plot the training loss\n",
    "train_loss_list = []\n",
    "# to plot the best recorded loss\n",
    "best_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    # declaring the list as global to plot validation loss\n",
    "    global valid_loss_list\n",
    "    # declaring the training loss list as global to plot\n",
    "    # the training loss\n",
    "    global train_loss_list\n",
    "    # declaring the best loss list as global to plot the\n",
    "    # best losses recorded\n",
    "    global best_loss_list\n",
    "    \n",
    "    # setting the seed to start from the same number as \n",
    "    # explained previously\n",
    "    set_seed_characteristics(seed)\n",
    "    \n",
    "    # adding dummy variables to the training set\n",
    "    train = addDummies(folds)\n",
    "\n",
    "    # extracting the validating rows numbers for the\n",
    "    # respective k fold values\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    # Dropping all the rows from the training set\n",
    "    # that does not belong to this kth fold\n",
    "    train_necessary_rows = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    # Dropping all the rows from the valiadtion set\n",
    "    # that does not belong to this kth fold\n",
    "    valid_necessary_rows = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # splitting the x and y values for training set\n",
    "    train_features, train_targets  = train_necessary_rows[feature_columns].values, train_necessary_rows[target_columns].values\n",
    "    # splitting the x and y values for test set\n",
    "    validation_features, validation_targets =  valid_necessary_rows[feature_columns].values, valid_necessary_rows[target_columns].values\n",
    "    \n",
    "    # Converting the training data to standard pytorch \n",
    "    # dataset class format\n",
    "    train_dataset = MoADataset(train_features, train_targets)\n",
    "    \n",
    "    # Converting the validation data to standard pytorch \n",
    "    # dataset class format\n",
    "    valid_dataset = MoADataset(validation_features, validation_targets)\n",
    "    \n",
    "    # calling the pytorch data loading utility for the\n",
    "    # training set\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # calling the pytorch data loading utility for the\n",
    "    # validation set  \n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Declaring the model and can be tuned here\n",
    "    # using the hyper parameters\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # moving the model to GPU if available,\n",
    "    # else will run it on CPU itself\n",
    "    model.to(device_code)\n",
    "    \n",
    "    # A standard optimizer. Adam optimizer is widely used\n",
    "    # because it combines the advantages of the Adaptive gradient\n",
    "    # algorithm and the root mean square propogation. Basically, it does\n",
    "    # not stick to one learning rate and adapts it to the problem. \n",
    "    # It is widely known to offer good results really fast.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # We use a learning rate scheduler to converge to the lowest\n",
    "    # loss faster. This is also seen to provide higher accuracy.\n",
    "    # This can be tuned.\n",
    "    # Some of the optimizers I tried here are\n",
    "    # optim.lr_scheduler.OneCycleLR\n",
    "    # optim.lr_scheduler.StepLR\n",
    "    \n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.05, div_factor=1.5e3, \n",
    "                                              max_lr=1e-2, epochs=max_epochs, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    # after research I saw that the Binary cross\n",
    "    # entropy loss with sigmoid layer works well\n",
    "    lossFunction = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # stops when the error starts increaseing. Setting the counter\n",
    "    # to track this\n",
    "    steps_before_early_stop = 0\n",
    "    # general out of fold array shape\n",
    "    out_of_fold = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    # declaring a very high value as an \n",
    "    # initial loss for each kth fold\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    # looping through the epochs\n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        # training the model\n",
    "        training_loss = trainingFunction(model, optimizer,scheduler, lossFunction, trainloader, device_code)\n",
    "        print('epoch : ',epoch,'>> training_loss : ',training_loss)\n",
    "        train_loss_list.append(training_loss)\n",
    "        validation_loss, validation_predictions = validationFunction(model, lossFunction, validloader, device_code)\n",
    "        print('epoch : ',epoch,'>> validation : ',validation_loss)\n",
    "        valid_loss_list.append(validation_loss)\n",
    "        \n",
    "        # checking if the loss is decreasing\n",
    "        if validation_loss < best_loss:\n",
    "            best_loss = validation_loss\n",
    "            best_loss_list.append(best_loss)\n",
    "            # Updating the out of fold predictions\n",
    "            out_of_fold[val_idx] = validation_predictions\n",
    "            # saving the model and data for this kth fold\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        # Handling the increasing loss by calling \n",
    "        # early stopping\n",
    "        elif(bool_early_stop == True):\n",
    "            \n",
    "            # breaks out of the loop when this happens\n",
    "            steps_before_early_stop += 1\n",
    "            if (steps_before_early_stop >= steps_early_stopping):\n",
    "                break\n",
    "    # adding dummy variables to the test set\n",
    "    test_ = addDummies(test)       \n",
    "    \n",
    "    # extracting the x_test\n",
    "    x_test = test_[feature_columns].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(num_features=num_features,num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # uploading the saved data for this kth fold\n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    # again uploading the model to GPU, if available\n",
    "    model.to(device_code)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    # evaluates the model\n",
    "    predictions = inferenceFunction(model, testloader, device_code)\n",
    "    \n",
    "    return out_of_fold, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKFold(number_of_folds, seed):\n",
    "    # standard size for the out of fold predictions\n",
    "    out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "    # same size for all of the predictions\n",
    "    predictions = np.zeros((len(test), len(target_columns)))\n",
    "    \n",
    "    for each_k_fold in range(number_of_folds):\n",
    "        print('Fold Number : ', each_k_fold)\n",
    "        out_of_fold_, pred_ = run_training(each_k_fold, seed)\n",
    "        \n",
    "        # adding all the predictions\n",
    "        predictions += pred_ / number_of_folds\n",
    "        # adding all the out of fold predictions\n",
    "        out_of_fold += out_of_fold_\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "    k_th_prediction = predictions\n",
    "    return out_of_fold, k_th_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number :  0\n",
      "epoch :  0 >> training_loss :  0.2788736069979875\n",
      "epoch :  0 >> validation :  0.021623456240471066\n",
      "epoch :  1 >> training_loss :  0.020091968256494272\n",
      "epoch :  1 >> validation :  0.01922281719101914\n",
      "epoch :  2 >> training_loss :  0.019972266159627747\n",
      "epoch :  2 >> validation :  0.01886744482506966\n",
      "epoch :  3 >> training_loss :  0.019043210343174313\n",
      "epoch :  3 >> validation :  0.018996690303601068\n",
      "epoch :  4 >> training_loss :  0.018774466394730235\n",
      "epoch :  4 >> validation :  0.018413769980442935\n",
      "epoch :  5 >> training_loss :  0.01869301253362842\n",
      "epoch :  5 >> validation :  0.01853232747264977\n",
      "epoch :  6 >> training_loss :  0.01865103912094365\n",
      "epoch :  6 >> validation :  0.018168202376571196\n",
      "epoch :  7 >> training_loss :  0.018572327146387617\n",
      "epoch :  7 >> validation :  0.01888334468520921\n",
      "epoch :  8 >> training_loss :  0.018362585228422414\n",
      "epoch :  8 >> validation :  0.018195184943234098\n",
      "epoch :  9 >> training_loss :  0.018180621188619864\n",
      "epoch :  9 >> validation :  0.01839715341941036\n",
      "epoch :  10 >> training_loss :  0.017992399317090926\n",
      "epoch :  10 >> validation :  0.017737267185644858\n",
      "epoch :  11 >> training_loss :  0.01772677853865468\n",
      "epoch :  11 >> validation :  0.017560527595723498\n",
      "epoch :  12 >> training_loss :  0.017529506098641002\n",
      "epoch :  12 >> validation :  0.01734824900932867\n",
      "epoch :  13 >> training_loss :  0.017258823679193208\n",
      "epoch :  13 >> validation :  0.01717964628839801\n",
      "epoch :  14 >> training_loss :  0.01701616107121758\n",
      "epoch :  14 >> validation :  0.01715383331837325\n",
      "epoch :  15 >> training_loss :  0.016877019105722074\n",
      "epoch :  15 >> validation :  0.01710507392497926\n",
      "------------------------\n",
      "Fold Number :  1\n",
      "epoch :  0 >> training_loss :  0.2791394925635794\n",
      "epoch :  0 >> validation :  0.021501707748092454\n",
      "epoch :  1 >> training_loss :  0.02014602518276028\n",
      "epoch :  1 >> validation :  0.019920575047104525\n",
      "epoch :  2 >> training_loss :  0.019292888320658518\n",
      "epoch :  2 >> validation :  0.020500779746036077\n",
      "epoch :  3 >> training_loss :  0.01898241023654523\n",
      "epoch :  3 >> validation :  0.019408218819519568\n",
      "epoch :  4 >> training_loss :  0.01884553834957921\n",
      "epoch :  4 >> validation :  0.018803634969838733\n",
      "epoch :  5 >> training_loss :  0.018704059833417767\n",
      "epoch :  5 >> validation :  0.01929768891041649\n",
      "epoch :  6 >> training_loss :  0.018495980099491452\n",
      "epoch :  6 >> validation :  0.018345469753418504\n",
      "epoch :  7 >> training_loss :  0.018502545138092144\n",
      "epoch :  7 >> validation :  0.0183179613748758\n",
      "epoch :  8 >> training_loss :  0.01830926013543554\n",
      "epoch :  8 >> validation :  0.018034464246111697\n",
      "epoch :  9 >> training_loss :  0.01814349767468546\n",
      "epoch :  9 >> validation :  0.018158412088864838\n",
      "epoch :  10 >> training_loss :  0.01796842050617156\n",
      "epoch :  10 >> validation :  0.017744970556091647\n",
      "epoch :  11 >> training_loss :  0.017735546859710113\n",
      "epoch :  11 >> validation :  0.01759479866074077\n",
      "epoch :  12 >> training_loss :  0.01754570741854284\n",
      "epoch :  12 >> validation :  0.017433413593419666\n",
      "epoch :  13 >> training_loss :  0.017299547661905702\n",
      "epoch :  13 >> validation :  0.017249190232491697\n",
      "epoch :  14 >> training_loss :  0.017085145907881467\n",
      "epoch :  14 >> validation :  0.017144549509574628\n",
      "epoch :  15 >> training_loss :  0.01694276431656402\n",
      "epoch :  15 >> validation :  0.01715218401032275\n",
      "------------------------\n",
      "Fold Number :  2\n",
      "epoch :  0 >> training_loss :  0.28062024895587695\n",
      "epoch :  0 >> validation :  0.021831682176682455\n",
      "epoch :  1 >> training_loss :  0.019925031827195832\n",
      "epoch :  1 >> validation :  0.02110225957786215\n",
      "epoch :  2 >> training_loss :  0.019255759826172954\n",
      "epoch :  2 >> validation :  0.01923344059494035\n",
      "epoch :  3 >> training_loss :  0.01897560269774302\n",
      "epoch :  3 >> validation :  0.01963105608291667\n",
      "epoch :  4 >> training_loss :  0.01888560847905667\n",
      "epoch :  4 >> validation :  0.018987211848384346\n",
      "epoch :  5 >> training_loss :  0.018881849539668663\n",
      "epoch :  5 >> validation :  0.019087364800788206\n",
      "epoch :  6 >> training_loss :  0.01880092287193174\n",
      "epoch :  6 >> validation :  0.018451588421032346\n",
      "epoch :  7 >> training_loss :  0.01856426177141459\n",
      "epoch :  7 >> validation :  0.018233612982620453\n",
      "epoch :  8 >> training_loss :  0.018412961470692053\n",
      "epoch :  8 >> validation :  0.018018708034450638\n",
      "epoch :  9 >> training_loss :  0.018320308147889118\n",
      "epoch :  9 >> validation :  0.01789587644603232\n",
      "epoch :  10 >> training_loss :  0.018012238172409326\n",
      "epoch :  10 >> validation :  0.017706910565752406\n",
      "epoch :  11 >> training_loss :  0.01781968524598557\n",
      "epoch :  11 >> validation :  0.01754140906870879\n",
      "epoch :  12 >> training_loss :  0.017585085947876392\n",
      "epoch :  12 >> validation :  0.017338143388644374\n",
      "epoch :  13 >> training_loss :  0.01736602078637351\n",
      "epoch :  13 >> validation :  0.017160253085452933\n",
      "epoch :  14 >> training_loss :  0.01719682110554498\n",
      "epoch :  14 >> validation :  0.017085314712262357\n",
      "epoch :  15 >> training_loss :  0.017056497793806635\n",
      "epoch :  15 >> validation :  0.0171179612135065\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# setting a standard seed number\n",
    "SEED = [55]\n",
    "# general out of fold array shape\n",
    "out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "# general predictions array shape\n",
    "predictions = np.zeros((len(test), len(target_columns)))\n",
    "\n",
    "# for seed in SEED:\n",
    "out_of_fold_, predictions_ = executeKFold(number_of_folds, SEED[0])\n",
    "out_of_fold += out_of_fold_ / len(SEED)\n",
    "predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_columns] = out_of_fold\n",
    "test[target_columns] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the logarithmic loss function applied to each drug-MoA annotation pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Cross Validation loss is :>>  0.015734850054263057\n"
     ]
    }
   ],
   "source": [
    "validation_df = training_targets_scored.drop(columns=target_columns).merge(train[['sig_id']+target_columns], on='sig_id', how='left').fillna(0)\n",
    "# True target values\n",
    "true_target = training_targets_scored[target_columns].values\n",
    "# Predicted target values\n",
    "predicted_target = validation_df[target_columns].values\n",
    "cross_validation_score = 0\n",
    "\n",
    "# Now we can calculate the cross entropy loss\n",
    "\n",
    "for i in range(len(target_columns)):\n",
    "    cross_validation_score_target = log_loss(true_target[:, i], predicted_target[:, i])\n",
    "    cross_validation_score += cross_validation_score_target / target.shape[1]  \n",
    "\n",
    "print(\" The Cross Validation loss is :>> \", cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Validation loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_loss_list)\n",
    "plt.title('Validation Loss')\n",
    "plt.savefig('valid_loss_list.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.title('Training loss')\n",
    "plt.savefig('train_loss_list.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Best recorded loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_loss_list)\n",
    "plt.title('Best Recorded loss')\n",
    "plt.savefig('best_loss_list.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
