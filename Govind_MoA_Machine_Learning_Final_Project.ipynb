{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action (MoA) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some of the important terms used in the headings of the tables are presented here:\n",
    "    \n",
    "    g - : signifies gene expression data\n",
    "    c - : signifies cell expression data\n",
    "    cp_type : indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\n",
    "    NOTE: (samples with control perturbations don't have MoAs)\n",
    "    cp_time - treatment duration (24,48,72) Hours\n",
    "    cp_dose - Dosage - HIGH or LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the multi label stratified k-fold \n",
    "# cross validator\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "# Initial random imports\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Importing pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device_code = 'cuda'\n",
    "else:\n",
    "    device_code = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the seed, so that every time the seed is started from the same number\n",
    "\n",
    "def set_seed_characteristics(seed=55):\n",
    "    # Setting a random seed value\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    # for guaranteering the reproducability of numbers by setting seed for NumPy\n",
    "    \n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    # for setting the seed for cuda or cpu\n",
    "    \n",
    "    torch.manual_seed(seed) \n",
    "\n",
    "    # To ensure that Pytorch doesnt just switch to the fastest possible algorithm but \n",
    "    # ensures that it selects a deterministic algorithm\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.read_csv('input/train_features.csv')\n",
    "# Reading the head rows and columns of train features\n",
    "training_features_head = training_features.head()\n",
    "\n",
    "training_targets_scored = pd.read_csv('input/train_targets_scored.csv')\n",
    "# Reading the head rows and columns of train targets scored\n",
    "training_targets_scored_head = training_targets_scored.head()\n",
    "\n",
    "testing_features = pd.read_csv('input/test_features.csv')\n",
    "# Reading the head rows and columns of train targets non-scored\n",
    "testing_features_head = testing_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n",
       "1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n",
       "2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n",
       "3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n",
       "4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0 -0.3981  0.2139  0.3801  0.4176  \n",
       "1  0.1522  0.1241  0.6077  0.7371  \n",
       "2 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - training features \n",
    "training_features_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_000644bb2                            0                       0   \n",
       "1  id_000779bfc                            0                       0   \n",
       "2  id_000a6266a                            0                       0   \n",
       "3  id_0015fd391                            0                       0   \n",
       "4  id_001626bd3                            0                       0   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0               0                               0   \n",
       "1               0                               0   \n",
       "2               0                               0   \n",
       "3               0                               0   \n",
       "4               0                               0   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               0   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                           0  ...                                      0   \n",
       "1                           0  ...                                      0   \n",
       "2                           0  ...                                      0   \n",
       "3                           0  ...                                      0   \n",
       "4                           0  ...                                      0   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0             0                0                  0   \n",
       "1             0                0                  0   \n",
       "2             0                0                  0   \n",
       "3             0                0                  0   \n",
       "4             0                0                  0   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                          0                                      0   \n",
       "1                          0                                      0   \n",
       "2                          0                                      0   \n",
       "3                          0                                      0   \n",
       "4                          0                                      0   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                0          0                           0              0  \n",
       "1                0          0                           0              0  \n",
       "2                0          0                           0              0  \n",
       "3                0          0                           0              0  \n",
       "4                0          0                           0              0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - train targets scored \n",
    "training_targets_scored_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5458</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>-0.5135</td>\n",
       "      <td>0.4408</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>-0.1644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>-0.1430</td>\n",
       "      <td>-0.2067</td>\n",
       "      <td>-0.2303</td>\n",
       "      <td>-0.1193</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0502</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>1.2080</td>\n",
       "      <td>-0.4522</td>\n",
       "      <td>-0.3652</td>\n",
       "      <td>-0.3319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>-0.1852</td>\n",
       "      <td>-1.0310</td>\n",
       "      <td>-1.3670</td>\n",
       "      <td>-0.3690</td>\n",
       "      <td>-0.5382</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.4764</td>\n",
       "      <td>-1.3810</td>\n",
       "      <td>-0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>-0.3911</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-1.4380</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>-1.3840</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>-1.9530</td>\n",
       "      <td>-1.0140</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-0.1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.5855</td>\n",
       "      <td>-1.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>-0.1784</td>\n",
       "      <td>-1.1200</td>\n",
       "      <td>-0.4325</td>\n",
       "      <td>-0.9005</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>-0.1305</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>-0.5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-1.2680</td>\n",
       "      <td>1.9130</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>-0.5864</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>-0.1580</td>\n",
       "      <td>1.0510</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>-0.2962</td>\n",
       "      <td>-0.5313</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>1.8380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_0004d9e33       trt_cp       24      D1 -0.5458  0.1306 -0.5135  0.4408   \n",
       "1  id_001897cda       trt_cp       72      D1 -0.1829  0.2320  1.2080 -0.4522   \n",
       "2  id_002429b5b  ctl_vehicle       24      D1  0.1852 -0.1404 -0.3911  0.1310   \n",
       "3  id_00276f245       trt_cp       24      D2  0.4828  0.1955  0.3825  0.4244   \n",
       "4  id_0027f1083       trt_cp       48      D1 -0.3979 -1.2680  1.9130  0.2057   \n",
       "\n",
       "      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n",
       "0  1.5500 -0.1644  ...  0.0981  0.7978 -0.1430 -0.2067 -0.2303 -0.1193   \n",
       "1 -0.3652 -0.3319  ... -0.1190 -0.1852 -1.0310 -1.3670 -0.3690 -0.5382   \n",
       "2 -1.4380  0.2455  ... -0.2261  0.3370 -1.3840  0.8604 -1.9530 -1.0140   \n",
       "3 -0.5855 -1.2020  ...  0.1260  0.1570 -0.1784 -1.1200 -0.4325 -0.9005   \n",
       "4 -0.5864 -0.0166  ...  0.4965  0.7578 -0.1580  1.0510  0.5742  1.0900   \n",
       "\n",
       "     c-96    c-97    c-98    c-99  \n",
       "0  0.0210 -0.0502  0.1510 -0.7750  \n",
       "1  0.0359 -0.4764 -1.3810 -0.7300  \n",
       "2  0.8662  1.0160  0.4924 -0.1942  \n",
       "3  0.8131 -0.1305  0.5645 -0.5809  \n",
       "4 -0.2962 -0.5313  0.9931  1.8380  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the head - test features\n",
    "testing_features_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset classes, training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch data loader implementation of MoA dataset\n",
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return train_tensor_dictionary\n",
    "\n",
    "# Pytorch data loader implementation of test dataset\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        test_tensor_dictionary = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return test_tensor_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch model for the MoA determination\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    # Instantiaing all the models before utilizing\n",
    "    # them later in the forward function.\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        \n",
    "        # super keyword used to access data from the parent\n",
    "        # pytorch.nn.Module class\n",
    "        super(Model, self).__init__()\n",
    "        # Applying batch normalization. This is done to standardize\n",
    "        # the input for each mini batches and will help reduce the\n",
    "        # number of epochs for which the training is done. This limits\n",
    "        # the covariate shift (this is the value by which the hidden\n",
    "        # layer values shift around) and allows to learn from a more \n",
    "        # stable set of data. Sometimes, it also allows for a\n",
    "        # higher learning rate.This is also used for regularization\n",
    "        # and helps reduce over fitting. Generally, if batch \n",
    "        # normalization is used, you can use a smaller dropout,\n",
    "        # which in turn means that lesser layers can be lost \n",
    "        # in every step.\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)        \n",
    "        # For regularization purposes the dropout is set\n",
    "        # This is done by setting a probablity. Random \n",
    "        # neural networks are picked at a probablity, say p\n",
    "        # or dropped at a probablity of 1-p. This is essential \n",
    "        # to prevent overfitiing of the model and also reduces\n",
    "        # the computation time. A fully connected neural network, if\n",
    "        # run without dropout will start forming dependancies between\n",
    "        # each other and this can lead to over-fitting.\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        # nn.utils.weight_norm : This is weight normalization. Usually,\n",
    "        #                        faster than batch normalization\n",
    "        # nn.Linear : Applying linear transform to the incoming data\n",
    "        #             and creates a single layer feed forward network.\n",
    "        # input size : num_features\n",
    "        # output size : hidden_size\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        # input size : hidden_size\n",
    "        # output size : hidden_size\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        # input size : hidden_size\n",
    "        # output size : num_targets\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    # The forward function basically defines the model\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def trainingFunction(model, optimizer, scheduler, lossFunction, trainloader, device_code):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    for training_data in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = training_data['x'].to(device_code), training_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        training_loss += loss.item()    \n",
    "    training_loss /= len(trainloader) \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate the model\n",
    "def validationFunction(model, lossFunction, validationloader, device_code):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_predictions = []   \n",
    "    for validation_data in validationloader:\n",
    "        inputs, targets = validation_data['x'].to(device_code), validation_data['y'].to(device_code)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, targets)\n",
    "        validation_loss += loss.item()\n",
    "        validation_predictions.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "    validation_loss /= len(validationloader)\n",
    "    validation_predictions = np.concatenate(validation_predictions)\n",
    "    return validation_loss, validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the inference function\n",
    "def inferenceFunction(model, inferenceloader, device_code):\n",
    "    model.eval()\n",
    "    inferences = [] \n",
    "    for data in inferenceloader:\n",
    "        inputs = data['x'].to(device_code)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        inferences.append(outputs.sigmoid().detach().cpu().numpy())   \n",
    "    inferences = np.concatenate(inferences)  \n",
    "    return inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dummy inserts to the cp_time and cp_dose columns\n",
    "# Usually done to categorical variables\n",
    "def addDummies(data):\n",
    "    dummy_data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return dummy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed_characteristics(seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating out the Gene expression Column and Cell Viability Column\n",
    "\n",
    "gene_expression = [g for g in training_features.columns if g.startswith('g-')]\n",
    "cell_viability = [c for c in training_features.columns if c.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our dimensions are really high, we can resort to \n",
    "# using PCA for dimensionality reduction, but is still able \n",
    "# to capture the characteristics of the data.\n",
    "\n",
    "# Now, this can be done by choosing a random dimension, and \n",
    "# having the same random state as before. By doing this\n",
    "# we observe that we do not encounter\n",
    "# any 'nan' errors during training.\n",
    "\n",
    "# Doing PCA for the Gene expression data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_genes = 20\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[gene_expression]), pd.DataFrame(testing_features[gene_expression])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_genes number of columns\n",
    "pca_genes = PCA(n_components = random_pca_dimension_genes, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_genes.fit_transform(data[gene_expression])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_genes = data_pca[:training_features.shape[0]] \n",
    "test_pca_genes = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_genes = pd.DataFrame(train_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "test_pca_genes = pd.DataFrame(test_pca_genes, columns=[f'pca_G-{i}' for i in range(random_pca_dimension_genes)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_genes), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_genes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing PCA for the Cell Viability Data\n",
    "\n",
    "# can choose any random number here\n",
    "random_pca_dimension_cells = 32\n",
    "\n",
    "# Concatenating the training and test set\n",
    "data = pd.concat([pd.DataFrame(training_features[cell_viability]), pd.DataFrame(testing_features[cell_viability])])\n",
    "\n",
    "# Performing PCA and converting to a random_pca_dimension_cells number of columns\n",
    "pca_cells = PCA(n_components = random_pca_dimension_cells, random_state=55)\n",
    "\n",
    "# Fitting the PCA transform\n",
    "data_pca = pca_cells.fit_transform(data[cell_viability])\n",
    "\n",
    "# Splitting the training and test columns\n",
    "train_pca_cells = data_pca[:training_features.shape[0]]\n",
    "test_pca_cells = data_pca[-testing_features.shape[0]:]\n",
    "\n",
    "# Converting training and testing  into Pandas data frame shape\n",
    "train_pca_cells = pd.DataFrame(train_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "test_pca_cells = pd.DataFrame(test_pca_cells, columns=[f'pca_C-{i}' for i in range(random_pca_dimension_cells)])\n",
    "\n",
    "# Concatenating these back to the original features\n",
    "training_features = pd.concat((training_features, train_pca_cells), axis=1)\n",
    "testing_features = pd.concat((testing_features, test_pca_cells), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a desired threshold to calculate the VarianceThreshold.\n",
    "# As per the math all the Features with a training-set variance \n",
    "# lower than this threshold will be removed.\n",
    "variancethreshold = VarianceThreshold(threshold=0.7)\n",
    "\n",
    "# Combining training and test features to create a single dataset\n",
    "combined_data = training_features.append(testing_features)\n",
    "\n",
    "# Fits to the data, before transforming it\n",
    "combined_data_transformed = variancethreshold.fit_transform(combined_data.iloc[:, 4:])\n",
    "\n",
    "# Extracting the training and the testing data out of the\n",
    "# transformed data\n",
    "training_features_transformed = combined_data_transformed[ : training_features.shape[0]]\n",
    "testing_features_transformed = combined_data_transformed[-testing_features.shape[0] : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the training features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "training_features = pd.DataFrame(training_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "training_features = pd.concat([training_features, pd.DataFrame(training_features_transformed)], axis=1)\n",
    "\n",
    "# Extracting the testing features in a suitable \n",
    "# pandas dataset format and numbering the columns\n",
    "# after the labels of 'sig_id', 'cp_type', 'cp_time', 'cp_dose'.\n",
    "\n",
    "testing_features = pd.DataFrame(testing_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4), columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "testing_features = pd.concat([testing_features, pd.DataFrame(testing_features_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the columns\n",
    "\n",
    "train = training_features.merge(training_targets_scored, on='sig_id')\n",
    "\n",
    "# Removing rows with cp_type as ctl_vehicle \n",
    "# since control perturbations have no MoAs\n",
    "# We are also manually setting the drop type as \n",
    "# true because we do not want to include them back \n",
    "# as a new column.\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "# Naturally, we have to get rid of them from the test dataset \n",
    "# as well\n",
    "\n",
    "test = testing_features[testing_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the columns of the drugs that are sold from\n",
    "# the train pandas dataframe\n",
    "\n",
    "target = train[training_targets_scored.columns]\n",
    "\n",
    "# Now that the ctl_vehicle drugs have been removed, we do not need\n",
    "# cp_type. So we can go ahead and remove that columns as well.\n",
    "\n",
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "# extracting the columns in the targets \n",
    "\n",
    "target_columns = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilabel stratified K Fold import causes a small warning and we do not want\n",
    "# to show that in the notebook.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "folds = train.copy()\n",
    "number_of_folds = 3\n",
    "\n",
    "# creating a 3 fold multilabel stratified K Fold\n",
    "multilabel_k_fold = MultilabelStratifiedKFold(n_splits = number_of_folds)\n",
    "\n",
    "# Standard k fold splitting. Here we are splitting into number_of_folds folds\n",
    "\n",
    "for fol, (train_folds, validation_folds) in enumerate(multilabel_k_fold.split(X=train, y=target)):\n",
    "    folds.loc[validation_folds, 'kfold'] = int(fol)\n",
    "    \n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# Isolating out the feature columns. This is done by first \n",
    "# Isolating the columns that are not present in the target\n",
    "# followed by extracting the columns except the sig_id and \n",
    "# kfold.\n",
    "\n",
    "feature_columns = [c for c in addDummies(folds).columns if c not in target_columns]\n",
    "feature_columns = [c for c in feature_columns if c not in ['kfold','sig_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "max_epochs = 15\n",
    "# When training neural networks, it is common to use \n",
    "# weight decay where after each update, the weights \n",
    "# are multiplied by a factor slightly less than 1\n",
    "WEIGHT_DECAY = 1e-5\n",
    "# deciding the initial learning rate\n",
    "# It controls how quickly or slowly a neural\n",
    "# network model can learn a model or a problem.\n",
    "lr = 1e-3\n",
    "# Boolean to decide on stopping early when the \n",
    "# validation_loss > best_loss\n",
    "bool_early_stop = True\n",
    "# steps to execute before early stopping\n",
    "steps_early_stopping= 10\n",
    "# number of features corresponding to the columns in the\n",
    "# targets\n",
    "num_features=len(feature_columns)\n",
    "# number of targets corresponding to the columns in the\n",
    "# features\n",
    "num_targets=len(target_columns)\n",
    "# in between neural netwrok size\n",
    "hidden_size=1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the training functions and performing the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot validation loss\n",
    "valid_loss_list = []\n",
    "# to plot the training loss\n",
    "train_loss_list = []\n",
    "# to plot the best recorded loss\n",
    "best_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    # declaring the list as global to plot validation loss\n",
    "    global valid_loss_list\n",
    "    # declaring the training loss list as global to plot\n",
    "    # the training loss\n",
    "    global train_loss_list\n",
    "    # declaring the best loss list as global to plot the\n",
    "    # best losses recorded\n",
    "    global best_loss_list\n",
    "    \n",
    "    # setting the seed to start from the same number as \n",
    "    # explained previously\n",
    "    set_seed_characteristics(seed)\n",
    "    \n",
    "    # adding dummy variables to the training set\n",
    "    train = addDummies(folds)\n",
    "\n",
    "    # extracting the validating rows numbers for the\n",
    "    # respective k fold values\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    # Dropping all the rows from the training set\n",
    "    # that does not belong to this kth fold\n",
    "    train_necessary_rows = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    # Dropping all the rows from the valiadtion set\n",
    "    # that does not belong to this kth fold\n",
    "    valid_necessary_rows = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # splitting the x and y values for training set\n",
    "    train_features, train_targets  = train_necessary_rows[feature_columns].values, train_necessary_rows[target_columns].values\n",
    "    # splitting the x and y values for test set\n",
    "    validation_features, validation_targets =  valid_necessary_rows[feature_columns].values, valid_necessary_rows[target_columns].values\n",
    "    \n",
    "    # Converting the training data to standard pytorch \n",
    "    # dataset class format\n",
    "    train_dataset = MoADataset(train_features, train_targets)\n",
    "    \n",
    "    # Converting the validation data to standard pytorch \n",
    "    # dataset class format\n",
    "    valid_dataset = MoADataset(validation_features, validation_targets)\n",
    "    \n",
    "    # calling the pytorch data loading utility for the\n",
    "    # training set\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # calling the pytorch data loading utility for the\n",
    "    # validation set  \n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Declaring the model and can be tuned here\n",
    "    # using the hyper parameters\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # moving the model to GPU if available,\n",
    "    # else will run it on CPU itself\n",
    "    model.to(device_code)\n",
    "    \n",
    "    # A standard optimizer. Adam optimizer is widely used\n",
    "    # because it combines the advantages of the Adaptive gradient\n",
    "    # algorithm and the root mean square propogation. Basically, it does\n",
    "    # not stick to one learning rate and adapts it to the problem. \n",
    "    # It is widely known to offer good results really fast.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # We use a learning rate scheduler to converge to the lowest\n",
    "    # loss faster. This is also seen to provide higher accuracy.\n",
    "    # This can be tuned.\n",
    "    # Some of the optimizers I tried here are\n",
    "    # optim.lr_scheduler.OneCycleLR\n",
    "    # optim.lr_scheduler.StepLR\n",
    "    \n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.05, div_factor=1.5e3, \n",
    "                                              max_lr=1e-2, epochs=max_epochs, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    # after research I saw that the Binary cross\n",
    "    # entroy loss with sigmoid later works well\n",
    "    lossFunction = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # stops when the error starts increaseing. Setting the counter\n",
    "    # to track this\n",
    "    steps_before_early_stop = 0\n",
    "    # general out of fold array shape\n",
    "    out_of_fold = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    # declaring a very high value as an \n",
    "    # initial loss for each kth fold\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    # looping through the epochs\n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        # training the model\n",
    "        training_loss = trainingFunction(model, optimizer,scheduler, lossFunction, trainloader, device_code)\n",
    "        print('epoch : ',epoch,'>> training_loss : ',training_loss)\n",
    "        train_loss_list.append(training_loss)\n",
    "        validation_loss, validation_predictions = validationFunction(model, lossFunction, validloader, device_code)\n",
    "        print('epoch : ',epoch,'>> validation : ',validation_loss)\n",
    "        valid_loss_list.append(validation_loss)\n",
    "        \n",
    "        # checking if the loss is decreasing\n",
    "        if validation_loss < best_loss:\n",
    "            best_loss = validation_loss\n",
    "            best_loss_list.append(best_loss)\n",
    "            # Updating the out of fold predictions\n",
    "            out_of_fold[val_idx] = validation_predictions\n",
    "            # saving the model and data for this kth fold\n",
    "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
    "        \n",
    "        # Handling the increasing loss by calling \n",
    "        # early stopping\n",
    "        elif(bool_early_stop == True):\n",
    "            \n",
    "            # breaks out of the loop when this happens\n",
    "            steps_before_early_stop += 1\n",
    "            if (steps_before_early_stop >= steps_early_stopping):\n",
    "                break\n",
    "    # adding dummy variables to the test set\n",
    "    test_ = addDummies(test)       \n",
    "    \n",
    "    # extracting the x_test\n",
    "    x_test = test_[feature_columns].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(num_features=num_features,num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    # uploading the saved data for this kth fold\n",
    "    model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))\n",
    "    # again uploading the model to GPU, if available\n",
    "    model.to(device_code)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    # evaluates the model\n",
    "    predictions = inferenceFunction(model, testloader, device_code)\n",
    "    \n",
    "    return out_of_fold, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKFold(number_of_folds, seed):\n",
    "    # standard size for the out of fold predictions\n",
    "    out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "    # same size for all of the predictions\n",
    "    predictions = np.zeros((len(test), len(target_columns)))\n",
    "    \n",
    "    for each_k_fold in range(number_of_folds):\n",
    "        print('Fold Number : ', each_k_fold)\n",
    "        out_of_fold_, pred_ = run_training(each_k_fold, seed)\n",
    "        \n",
    "        # adding all the predictions\n",
    "        predictions += pred_ / number_of_folds\n",
    "        # adding all the out of fold predictions\n",
    "        out_of_fold += out_of_fold_\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "    k_th_prediction = predictions\n",
    "    return out_of_fold, k_th_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number :  0\n",
      "epoch :  0 >> training_loss :  0.22010354647274621\n",
      "epoch :  0 >> validation :  0.023666419461369513\n",
      "epoch :  1 >> training_loss :  0.019186532165546083\n",
      "epoch :  1 >> validation :  0.018038645216628263\n",
      "epoch :  2 >> training_loss :  0.01805579964494471\n",
      "epoch :  2 >> validation :  0.017761908309615177\n",
      "epoch :  3 >> training_loss :  0.017867758304824215\n",
      "epoch :  3 >> validation :  0.017857895232737064\n",
      "epoch :  4 >> training_loss :  0.017903095359332436\n",
      "epoch :  4 >> validation :  0.01778543307243482\n",
      "epoch :  5 >> training_loss :  0.017865373090104764\n",
      "epoch :  5 >> validation :  0.01771177589569403\n",
      "epoch :  6 >> training_loss :  0.017801803337434495\n",
      "epoch :  6 >> validation :  0.017754284640693146\n",
      "epoch :  7 >> training_loss :  0.017625045023175308\n",
      "epoch :  7 >> validation :  0.01749473760795334\n",
      "epoch :  8 >> training_loss :  0.017523331644916377\n",
      "epoch :  8 >> validation :  0.01738321535775195\n",
      "epoch :  9 >> training_loss :  0.017271582281225113\n",
      "epoch :  9 >> validation :  0.017173669973145362\n",
      "epoch :  10 >> training_loss :  0.0169291109594976\n",
      "epoch :  10 >> validation :  0.017004118390057398\n",
      "epoch :  11 >> training_loss :  0.016468546617629747\n",
      "epoch :  11 >> validation :  0.01682888491322165\n",
      "epoch :  12 >> training_loss :  0.01609259536774528\n",
      "epoch :  12 >> validation :  0.01646154224872589\n",
      "epoch :  13 >> training_loss :  0.015670125881071695\n",
      "epoch :  13 >> validation :  0.016405823041239512\n",
      "epoch :  14 >> training_loss :  0.015413479928301412\n",
      "epoch :  14 >> validation :  0.016400540684876234\n",
      "------------------------\n",
      "Fold Number :  1\n",
      "epoch :  0 >> training_loss :  0.21934205309516347\n",
      "epoch :  0 >> validation :  0.019624629722017308\n",
      "epoch :  1 >> training_loss :  0.019233085597381322\n",
      "epoch :  1 >> validation :  0.018496299891368202\n",
      "epoch :  2 >> training_loss :  0.018104698191758847\n",
      "epoch :  2 >> validation :  0.01825582786746647\n",
      "epoch :  3 >> training_loss :  0.01792455349507941\n",
      "epoch :  3 >> validation :  0.017925553493525672\n",
      "epoch :  4 >> training_loss :  0.017902072689874204\n",
      "epoch :  4 >> validation :  0.01784542274215947\n",
      "epoch :  5 >> training_loss :  0.017856515923669505\n",
      "epoch :  5 >> validation :  0.017887767493400885\n",
      "epoch :  6 >> training_loss :  0.01782956671408951\n",
      "epoch :  6 >> validation :  0.017674128387285316\n",
      "epoch :  7 >> training_loss :  0.01767263380102976\n",
      "epoch :  7 >> validation :  0.01744032489216846\n",
      "epoch :  8 >> training_loss :  0.01752583795597199\n",
      "epoch :  8 >> validation :  0.017471135828806005\n",
      "epoch :  9 >> training_loss :  0.017338152340405893\n",
      "epoch :  9 >> validation :  0.017311251139187293\n",
      "epoch :  10 >> training_loss :  0.017011438695689475\n",
      "epoch :  10 >> validation :  0.016974642556970534\n",
      "epoch :  11 >> training_loss :  0.016557448482604528\n",
      "epoch :  11 >> validation :  0.016709625607599383\n",
      "epoch :  12 >> training_loss :  0.0161838825938483\n",
      "epoch :  12 >> validation :  0.016527956505508527\n",
      "epoch :  13 >> training_loss :  0.015817197255269668\n",
      "epoch :  13 >> validation :  0.01643166460258805\n",
      "epoch :  14 >> training_loss :  0.01558316311103548\n",
      "epoch :  14 >> validation :  0.016377129405736924\n",
      "------------------------\n",
      "Fold Number :  2\n",
      "epoch :  0 >> training_loss :  0.21958386233507546\n",
      "epoch :  0 >> validation :  0.019972299833012665\n",
      "epoch :  1 >> training_loss :  0.019250208373673618\n",
      "epoch :  1 >> validation :  0.018394408690864627\n",
      "epoch :  2 >> training_loss :  0.01816932274248272\n",
      "epoch :  2 >> validation :  0.017732043483335038\n",
      "epoch :  3 >> training_loss :  0.017910432770002357\n",
      "epoch :  3 >> validation :  0.017841520605851775\n",
      "epoch :  4 >> training_loss :  0.01798885790671844\n",
      "epoch :  4 >> validation :  0.01784432004813267\n",
      "epoch :  5 >> training_loss :  0.018013966774088067\n",
      "epoch :  5 >> validation :  0.017730359886975394\n",
      "epoch :  6 >> training_loss :  0.01786304819173948\n",
      "epoch :  6 >> validation :  0.017437460224913513\n",
      "epoch :  7 >> training_loss :  0.017710901886289817\n",
      "epoch :  7 >> validation :  0.017432569963452608\n",
      "epoch :  8 >> training_loss :  0.017609727410314906\n",
      "epoch :  8 >> validation :  0.017427707609275114\n",
      "epoch :  9 >> training_loss :  0.017423871481652864\n",
      "epoch :  9 >> validation :  0.01721639859935512\n",
      "epoch :  10 >> training_loss :  0.0170545495688655\n",
      "epoch :  10 >> validation :  0.01680418574453696\n",
      "epoch :  11 >> training_loss :  0.01665241021955768\n",
      "epoch :  11 >> validation :  0.01654776910562878\n",
      "epoch :  12 >> training_loss :  0.016221660986445095\n",
      "epoch :  12 >> validation :  0.01634012415357258\n",
      "epoch :  13 >> training_loss :  0.01584852556393006\n",
      "epoch :  13 >> validation :  0.016212097830746484\n",
      "epoch :  14 >> training_loss :  0.015554520996962572\n",
      "epoch :  14 >> validation :  0.016224722135002197\n",
      "------------------------\n",
      " The Cross Validation loss is :>>  0.014994091669228132\n"
     ]
    }
   ],
   "source": [
    "# setting a standard seed number\n",
    "SEED = [55]\n",
    "# general out of fold array shape\n",
    "out_of_fold = np.zeros((len(train), len(target_columns)))\n",
    "# general predictions array shape\n",
    "predictions = np.zeros((len(test), len(target_columns)))\n",
    "\n",
    "# for seed in SEED:\n",
    "out_of_fold_, predictions_ = executeKFold(number_of_folds, SEED[0])\n",
    "out_of_fold += out_of_fold_ / len(SEED)\n",
    "predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_columns] = out_of_fold\n",
    "test[target_columns] = predictions\n",
    "\n",
    "validation_df = training_targets_scored.drop(columns=target_columns).merge(train[['sig_id']+target_columns], on='sig_id', how='left').fillna(0)\n",
    "# True target values\n",
    "true_target = training_targets_scored[target_columns].values\n",
    "# Predicted target values\n",
    "predicted_target = validation_df[target_columns].values\n",
    "cross_validation_score = 0\n",
    "\n",
    "# Now we can calculate the cross entropy loss\n",
    "\n",
    "for i in range(len(target_columns)):\n",
    "    cross_validation_score_target = log_loss(true_target[:, i], predicted_target[:, i])\n",
    "    cross_validation_score += cross_validation_score_target / target.shape[1]  \n",
    "\n",
    "print(\" The Cross Validation loss is :>> \", cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Validation loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f058c0ef820>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f051ed69640>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Best recorded loss for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f058c0af430>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
